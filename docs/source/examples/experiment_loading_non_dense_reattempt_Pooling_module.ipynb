{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26bec45",
   "metadata": {},
   "source": [
    "# Experiment Notebook\n",
    "Load .onnx and Verify Embedding without ML-Commons API to see if the problem is with ML-Commons API or the .onnx file itself\n",
    "\n",
    "Reference: https://github.com/SidJain1412/sentence-transformers/blob/master/examples/onnx/onnx_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7fcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d30d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"TracerWarning: torch.tensor\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"using SSL with verify_certs=False is insecure.\")\n",
    "\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel\n",
    "# import mlcommon to later register the model to OpenSearch Cluster\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5942be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_URL = 'https://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837bd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_client(cluster_url = CLUSTER_URL,\n",
    "                  username='admin',\n",
    "                  password='admin'):\n",
    "    '''\n",
    "    Get OpenSearch client\n",
    "    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443\n",
    "    :return: OpenSearch client\n",
    "    '''\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url],\n",
    "        http_auth=(username, password),\n",
    "        verify_certs=False\n",
    "    )\n",
    "    return client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9219ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/opensearchpy/connection/http_urllib3.py:199: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = get_os_client()\n",
    "\n",
    "# Connect to ml_common client with OpenSearch client\n",
    "ml_client = MLCommonClient(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b935d5",
   "metadata": {},
   "source": [
    "## Trace the Model in Onnx Using save_as_onnx\n",
    "See `opensearch_py_ml/ml_models/sentencetransformermodel.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9f10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
    "folder_path='sentence-transformers-onxx/msmarco-distilbert-base-tas-b'\n",
    "model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "model_path = os.path.join(folder_path, \"onnx\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f270c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 15\n",
      "Loading pipeline (model: sentence-transformers/msmarco-distilbert-base-tas-b, tokenizer: sentence-transformers/msmarco-distilbert-base-tas-b)\n",
      "Creating folder sentence-transformers-onxx/msmarco-distilbert-base-tas-b/onnx\n",
      "Using framework PyTorch: 1.13.1+cu117\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file is saved to  sentence-transformers-onxx/msmarco-distilbert-base-tas-b/onnx/msmarco-distilbert-base-tas-b.onnx\n",
      "zip file is saved to  sentence-transformers-onxx/msmarco-distilbert-base-tas-b/msmarco-distilbert-base-tas-b.zip \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case I: Initiate SentenceTransformerModel and Call save_as_onnx\n",
    "\n",
    "# pre_trained_model = SentenceTransformerModel(model_id=model_id, folder_path=folder_path, overwrite=True)\n",
    "# model_path_onnx = pre_trained_model.save_as_onnx(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case II: Repeat what save_as_onnx function does\n",
    "\n",
    "# from transformers.convert_graph_to_onnx import convert\n",
    "# from pathlib import Path\n",
    "\n",
    "# model = SentenceTransformer(model_id)\n",
    "# folder_path='sentence-transformers-onxx/distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "# model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "\n",
    "# model_path = os.path.join(folder_path, \"onnx\", model_name)\n",
    "        \n",
    "# convert(\n",
    "#     framework=\"pt\",\n",
    "#     model=model_id,\n",
    "#     output=Path(model_path),\n",
    "#     opset=15,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c474d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case III: Already run demo_tracing_model_torch_script_onnx_dense notebook \n",
    "\n",
    "# Skip to next step since we already have .onnx at model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8e004",
   "metadata": {},
   "source": [
    "## Creating an ONNX Inference Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b72e10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "\n",
    "# Constants from the performance optimization available in onnxruntime\n",
    "# It needs to be done before importing onnxruntime\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "from onnxruntime import InferenceSession, SessionOptions, get_all_providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d3b848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa80c4d",
   "metadata": {},
   "source": [
    "## Initialize pooling function to convert model sequence outputs to pooled outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08444ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def cls_pooling(model_output, attention_mask):\n",
    "#     return model_output[0][:,0]\n",
    "\n",
    "from sentence_transformers.models import Pooling\n",
    "pooling_layer = Pooling(768, pooling_mode_cls_token=True, pooling_mode_mean_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd18a1",
   "metadata": {},
   "source": [
    "## Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "763f1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\", \"very very long random sentence for testing\"]\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "auto_features = autotokenizer(\n",
    "            input_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7de10b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='sentence-transformers/msmarco-distilbert-base-tas-b', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autotokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00aef0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2034, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2117, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2200, 2200, 2146, 6721, 6251, 2005, 5604,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b0d42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {k: v.cpu().detach().numpy() for k, v in auto_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "127e742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[ 101, 2034, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2117, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2200, 2200, 2146, 6721, 6251, 2005, 5604,  102]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc4bdf",
   "metadata": {},
   "source": [
    "# Get model embedding outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ed70ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0d42ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37953554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b73efeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c81ed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_embeddings': tensor([[[ 0.2192, -0.2669, -0.2511,  ...,  0.0324, -0.3444, -0.0308],\n",
       "          [-0.1659, -0.2614, -0.5352,  ...,  0.2587, -0.1672, -0.2693],\n",
       "          [ 0.3557, -0.1637, -0.1883,  ...,  0.0900, -0.5482, -0.4730],\n",
       "          ...,\n",
       "          [ 0.3443, -0.3381, -0.1119,  ..., -0.0030, -0.3614, -0.1020],\n",
       "          [ 0.3628, -0.3531, -0.0856,  ..., -0.0109, -0.3690, -0.0990],\n",
       "          [ 0.3631, -0.3556, -0.1083,  ..., -0.0015, -0.3709, -0.0968]],\n",
       " \n",
       "         [[-0.0738, -0.4391, -0.0976,  ...,  0.0442, -0.1356, -0.3168],\n",
       "          [ 0.1501, -0.7653, -0.1249,  ...,  0.0637,  0.1336, -0.4225],\n",
       "          [ 0.1538, -0.2468,  0.0779,  ...,  0.1835, -0.3914, -0.5732],\n",
       "          ...,\n",
       "          [ 0.0661, -0.4476,  0.0596,  ...,  0.0086, -0.2125, -0.3663],\n",
       "          [ 0.0722, -0.4625,  0.0890,  ...,  0.0094, -0.2128, -0.3687],\n",
       "          [ 0.0680, -0.4786,  0.0622,  ...,  0.0096, -0.2001, -0.3937]],\n",
       " \n",
       "         [[ 0.4373, -0.6149, -0.1181,  ...,  0.2216, -0.3373, -0.0765],\n",
       "          [ 0.3838, -0.4288, -0.1162,  ...,  0.3549, -0.4408,  0.1906],\n",
       "          [ 0.3230, -0.4301, -0.1322,  ...,  0.3421, -0.4360,  0.1797],\n",
       "          ...,\n",
       "          [ 0.4455, -0.5739, -0.1169,  ...,  0.3618, -0.1620, -0.0039],\n",
       "          [ 0.5289, -0.6388, -0.1694,  ...,  0.0728, -0.1962, -0.2680],\n",
       "          [ 0.6783, -0.3765, -0.2818,  ...,  0.4963, -0.3674, -0.3462]]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'sentence_embedding': tensor([[ 0.2192, -0.2669, -0.2511,  ...,  0.0324, -0.3444, -0.0308],\n",
       "         [-0.0738, -0.4391, -0.0976,  ...,  0.0442, -0.1356, -0.3168],\n",
       "         [ 0.4373, -0.6149, -0.1181,  ...,  0.2216, -0.3373, -0.0765]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "features = {\n",
    "    'token_embeddings':  torch.from_numpy(ort_outs[0]),\n",
    "    'attention_mask': torch.from_numpy(ort_inputs['attention_mask'])\n",
    "}\n",
    "pooling_layer.forward(features)\n",
    "# sentence_embeddings = cls_pooling(ort_outs, ort_inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea4dea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = features['sentence_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e63e4c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe53a",
   "metadata": {},
   "source": [
    "## Verify Embedidngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2e0598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = SentenceTransformer(model_id) # From Huggingface\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "355e6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_onnx = [\n",
    "            sentence_embeddings[i]\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8de2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "None\n",
      "1\n",
      "None\n",
      "2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019f178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
