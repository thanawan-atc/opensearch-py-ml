{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26bec45",
   "metadata": {},
   "source": [
    "# Experiment Notebook\n",
    "Load .onnx and Verify Embedding without ML-Commons API to see if the problem is with ML-Commons API or the .onnx file itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7fcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d30d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"TracerWarning: torch.tensor\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"using SSL with verify_certs=False is insecure.\")\n",
    "\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel\n",
    "# import mlcommon to later register the model to OpenSearch Cluster\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5942be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_URL = 'https://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "837bd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_client(cluster_url = CLUSTER_URL,\n",
    "                  username='admin',\n",
    "                  password='admin'):\n",
    "    '''\n",
    "    Get OpenSearch client\n",
    "    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443\n",
    "    :return: OpenSearch client\n",
    "    '''\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url],\n",
    "        http_auth=(username, password),\n",
    "        verify_certs=False\n",
    "    )\n",
    "    return client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9219ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/opensearchpy/connection/http_urllib3.py:199: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = get_os_client()\n",
    "\n",
    "# Connect to ml_common client with OpenSearch client\n",
    "ml_client = MLCommonClient(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b935d5",
   "metadata": {},
   "source": [
    "## Trace the Model in Onnx Using save_as_onnx\n",
    "See `opensearch_py_ml/ml_models/sentencetransformermodel.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9f10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "folder_path='sentence-transformers-onxx/distiluse-base-multilingual-cased-v1'\n",
    "model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "model_path = os.path.join(folder_path, \"onnx\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f270c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case I: Initiate SentenceTransformerModel and Call save_as_onnx\n",
    "\n",
    "# pre_trained_model = SentenceTransformerModel(model_id=model_id, folder_path=folder_path, overwrite=True)\n",
    "# model_path_onnx = pre_trained_model.save_as_onnx(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case II: Repeat what save_as_onnx function does\n",
    "\n",
    "# from transformers.convert_graph_to_onnx import convert\n",
    "# from pathlib import Path\n",
    "\n",
    "# model = SentenceTransformer(model_id)\n",
    "# folder_path='sentence-transformers-onxx/distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "# model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "\n",
    "# model_path = os.path.join(folder_path, \"onnx\", model_name)\n",
    "        \n",
    "# convert(\n",
    "#     framework=\"pt\",\n",
    "#     model=model_id,\n",
    "#     output=Path(model_path),\n",
    "#     opset=15,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c474d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case III: Already run demo_tracing_model_torch_script_onnx_dense notebook \n",
    "\n",
    "# Skip to next step since we already have .onnx at model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8e004",
   "metadata": {},
   "source": [
    "## Load Onnx Model to Check Our .onnx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b72e10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d3b848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a human readable representation of the graph\n",
    "# print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe53a",
   "metadata": {},
   "source": [
    "## Verify Embedidngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aded6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93709208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\", \"very very long random sentence for testing\"]\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "auto_features = autotokenizer(\n",
    "            input_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b997b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='sentence-transformers/distiluse-base-multilingual-cased-v1', vocab_size=119547, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autotokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "782b63e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d70b4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {k: v.cpu().detach().numpy() for k, v in auto_features.items()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc7807",
   "metadata": {},
   "source": [
    "# Wrong Output Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abf3bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ffbec21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "046fdd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 768)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2e0598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = SentenceTransformer(model_id) # From Huggingface\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "355e6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_onnx = [\n",
    "            ort_outs[0][i]\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8de2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\n(shapes (512,), (9, 768) mismatch)\n x: array([ 1.097567e-02,  6.483248e-02, -4.571173e-02,  9.350104e-02,\n       -2.485733e-02, -3.051357e-02,  8.830560e-03,  1.258769e-02,\n        8.662871e-03, -4.904142e-02,  5.009779e-04, -6.247674e-03,...\n y: array([[-9.318674e-02,  4.319992e-02,  1.432451e-01, ..., -1.102899e-01,\n         9.420902e-02, -3.694843e-03],\n       [-1.011766e-01,  2.413086e-02,  1.626917e-01, ..., -7.624748e-02,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_sentences)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_embedding_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_data_onnx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:778\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    772\u001b[0m         reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(dtypes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mismatch)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    773\u001b[0m     msg \u001b[38;5;241m=\u001b[39m build_err_msg([x, y],\n\u001b[1;32m    774\u001b[0m                         err_msg\n\u001b[1;32m    775\u001b[0m                         \u001b[38;5;241m+\u001b[39m reason,\n\u001b[1;32m    776\u001b[0m                         verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    777\u001b[0m                         names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 778\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    780\u001b[0m flagged \u001b[38;5;241m=\u001b[39m bool_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isnumber(x) \u001b[38;5;129;01mand\u001b[39;00m isnumber(y):\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\n(shapes (512,), (9, 768) mismatch)\n x: array([ 1.097567e-02,  6.483248e-02, -4.571173e-02,  9.350104e-02,\n       -2.485733e-02, -3.051357e-02,  8.830560e-03,  1.258769e-02,\n        8.662871e-03, -4.904142e-02,  5.009779e-04, -6.247674e-03,...\n y: array([[-9.318674e-02,  4.319992e-02,  1.432451e-01, ..., -1.102899e-01,\n         9.420902e-02, -3.694843e-03],\n       [-1.011766e-01,  2.413086e-02,  1.626917e-01, ..., -7.624748e-02,..."
     ]
    }
   ],
   "source": [
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f863f7",
   "metadata": {},
   "source": [
    "## More Info: convert function\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/convert_graph_to_onnx.py#L387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55a5a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert(\n",
    "#     framework: str,\n",
    "#     model: str,\n",
    "#     output: Path,\n",
    "#     opset: int,\n",
    "#     tokenizer: Optional[str] = None,\n",
    "#     use_external_format: bool = False,\n",
    "#     pipeline_name: str = \"feature-extraction\",\n",
    "#     **model_kwargs,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Convert the pipeline object to the ONNX Intermediate Representation (IR) format\n",
    "\n",
    "#     Args:\n",
    "#         framework: The framework the pipeline is backed by (\"pt\" or \"tf\")\n",
    "#         model: The name of the model to load for the pipeline\n",
    "#         output: The path where the ONNX graph will be stored\n",
    "#         opset: The actual version of the ONNX operator set to use\n",
    "#         tokenizer: The name of the model to load for the pipeline, default to the model's name if not provided\n",
    "#         use_external_format:\n",
    "#             Split the model definition from its parameters to allow model bigger than 2GB (PyTorch only)\n",
    "#         pipeline_name: The kind of pipeline to instantiate (ner, question-answering, etc.)\n",
    "#         model_kwargs: Keyword arguments to be forwarded to the model constructor\n",
    "\n",
    "#     Returns:\n",
    "\n",
    "#     \"\"\"\n",
    "#     warnings.warn(\n",
    "#         \"The `transformers.convert_graph_to_onnx` package is deprecated and will be removed in version 5 of\"\n",
    "#         \" Transformers\",\n",
    "#         FutureWarning,\n",
    "#     )\n",
    "#     print(f\"ONNX opset version set to: {opset}\")\n",
    "\n",
    "#     # Load the pipeline\n",
    "#     nlp = load_graph_from_args(pipeline_name, framework, model, tokenizer, **model_kwargs)\n",
    "\n",
    "#     if not output.parent.exists():\n",
    "#         print(f\"Creating folder {output.parent}\")\n",
    "#         makedirs(output.parent.as_posix())\n",
    "#     elif len(listdir(output.parent.as_posix())) > 0:\n",
    "#         raise Exception(f\"Folder {output.parent.as_posix()} is not empty, aborting conversion\")\n",
    "\n",
    "#     # Export the graph\n",
    "#     if framework == \"pt\":\n",
    "#         convert_pytorch(nlp, opset, output, use_external_format)\n",
    "#     else:\n",
    "#         convert_tensorflow(nlp, opset, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aadab6",
   "metadata": {},
   "source": [
    "## More Info: Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e3d9a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"output_0\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: 1\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_param: \"batch\"\n",
       "      }\n",
       "      dim {\n",
       "        dim_param: \"sequence\"\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 768\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "208526b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"input_ids\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: 7\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_param: \"batch\"\n",
       "      }\n",
       "      dim {\n",
       "        dim_param: \"sequence\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"attention_mask\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: 7\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_param: \"batch\"\n",
       "      }\n",
       "      dim {\n",
       "        dim_param: \"sequence\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model.graph.input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a203d",
   "metadata": {},
   "source": [
    "## More Info: Modules (convert function calls load_graph_from_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fd367cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline (model: sentence-transformers/distiluse-base-multilingual-cased-v1, tokenizer: sentence-transformers/distiluse-base-multilingual-cased-v1)\n"
     ]
    }
   ],
   "source": [
    "from transformers.convert_graph_to_onnx import load_graph_from_args\n",
    "nlp = load_graph_from_args(\"feature-extraction\", \"pt\", model_id, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f00e8757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d67d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/serialization\n",
    "# https://github.com/oborchers/sentence-transformers/blob/master/examples/onnx_inference/onnx_inference.ipynb\n",
    "# https://github.com/UKPLab/sentence-transformers/pull/668"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d098f2",
   "metadata": {},
   "source": [
    "## Compare with Embedding from ML-Commons API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4ac2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_commons_embedding_output_onnx = ml_client.generate_embedding(\"WpL35okBqzTvNQeA6Vit\", input_sentences)\n",
    "ml_commons_embedding_data_onnx = [\n",
    "            ml_commons_embedding_output_onnx[\"inference_results\"][i][\"output\"][0][\"data\"]\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8344a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\n(shapes (768,), (9, 768) mismatch)\n x: array([-8.156287e-02,  3.827157e-02,  1.071574e-01, -1.202194e-03,\n       -5.243819e-02, -4.310886e-02, -1.101768e-01, -1.975697e-03,\n       -5.380076e-03,  9.543222e-02, -2.704400e-02, -6.535825e-02,...\n y: array([[-9.318674e-02,  4.319992e-02,  1.432451e-01, ..., -1.102899e-01,\n         9.420902e-02, -3.694843e-03],\n       [-1.011766e-01,  2.413086e-02,  1.626917e-01, ..., -7.624748e-02,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_sentences)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mml_commons_embedding_data_onnx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_data_onnx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:778\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    772\u001b[0m         reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(dtypes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mismatch)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    773\u001b[0m     msg \u001b[38;5;241m=\u001b[39m build_err_msg([x, y],\n\u001b[1;32m    774\u001b[0m                         err_msg\n\u001b[1;32m    775\u001b[0m                         \u001b[38;5;241m+\u001b[39m reason,\n\u001b[1;32m    776\u001b[0m                         verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    777\u001b[0m                         names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 778\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    780\u001b[0m flagged \u001b[38;5;241m=\u001b[39m bool_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isnumber(x) \u001b[38;5;129;01mand\u001b[39;00m isnumber(y):\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\n(shapes (768,), (9, 768) mismatch)\n x: array([-8.156287e-02,  3.827157e-02,  1.071574e-01, -1.202194e-03,\n       -5.243819e-02, -4.310886e-02, -1.101768e-01, -1.975697e-03,\n       -5.380076e-03,  9.543222e-02, -2.704400e-02, -6.535825e-02,...\n y: array([[-9.318674e-02,  4.319992e-02,  1.432451e-01, ..., -1.102899e-01,\n         9.420902e-02, -3.694843e-03],\n       [-1.011766e-01,  2.413086e-02,  1.626917e-01, ..., -7.624748e-02,..."
     ]
    }
   ],
   "source": [
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(ml_commons_embedding_data_onnx[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113037e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://neuml.hashnode.dev/export-and-run-models-with-onnx\n",
    "# https://colab.research.google.com/github/neuml/txtai/blob/master/examples/18_Export_and_run_models_with_ONNX.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
