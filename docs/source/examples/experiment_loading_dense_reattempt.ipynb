{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26bec45",
   "metadata": {},
   "source": [
    "# Experiment Notebook\n",
    "Load .onnx and Verify Embedding without ML-Commons API to see if the problem is with ML-Commons API or the .onnx file itself\n",
    "\n",
    "Reference: https://github.com/SidJain1412/sentence-transformers/blob/master/examples/onnx/onnx_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7fcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d30d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"TracerWarning: torch.tensor\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"using SSL with verify_certs=False is insecure.\")\n",
    "\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel\n",
    "# import mlcommon to later register the model to OpenSearch Cluster\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5942be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_URL = 'https://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837bd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_client(cluster_url = CLUSTER_URL,\n",
    "                  username='admin',\n",
    "                  password='admin'):\n",
    "    '''\n",
    "    Get OpenSearch client\n",
    "    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443\n",
    "    :return: OpenSearch client\n",
    "    '''\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url],\n",
    "        http_auth=(username, password),\n",
    "        verify_certs=False\n",
    "    )\n",
    "    return client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9219ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/opensearchpy/connection/http_urllib3.py:199: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = get_os_client()\n",
    "\n",
    "# Connect to ml_common client with OpenSearch client\n",
    "ml_client = MLCommonClient(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b935d5",
   "metadata": {},
   "source": [
    "## Trace the Model in Onnx Using save_as_onnx\n",
    "See `opensearch_py_ml/ml_models/sentencetransformermodel.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9f10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/distiluse-base-multilingual-cased-v2\"\n",
    "folder_path='sentence-transformers-onxx/distiluse-base-multilingual-cased-v2'\n",
    "model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "model_path = os.path.join(folder_path, \"onnx\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f270c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)6015c/.gitattributes: 100%|██████| 690/690 [00:00<00:00, 112kB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|█████| 190/190 [00:00<00:00, 32.3kB/s]\n",
      "Downloading (…)/2_Dense/config.json: 100%|█████| 114/114 [00:00<00:00, 69.7kB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.58M/1.58M [00:00<00:00, 29.0MB/s]\n",
      "Downloading (…)ff6066015c/README.md: 100%|█| 2.38k/2.38k [00:00<00:00, 1.54MB/s]\n",
      "Downloading (…)6066015c/config.json: 100%|██████| 610/610 [00:00<00:00, 367kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|█████| 122/122 [00:00<00:00, 75.2kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 539M/539M [00:01<00:00, 293MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|███| 53.0/53.0 [00:00<00:00, 10.1kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████| 112/112 [00:00<00:00, 65.9kB/s]\n",
      "Downloading (…)6015c/tokenizer.json: 100%|█| 1.96M/1.96M [00:00<00:00, 26.8MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████| 531/531 [00:00<00:00, 332kB/s]\n",
      "Downloading (…)ff6066015c/vocab.txt: 100%|███| 996k/996k [00:00<00:00, 43.3MB/s]\n",
      "Downloading (…)066015c/modules.json: 100%|██████| 341/341 [00:00<00:00, 218kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 15\n",
      "Loading pipeline (model: sentence-transformers/distiluse-base-multilingual-cased-v2, tokenizer: sentence-transformers/distiluse-base-multilingual-cased-v2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████| 610/610 [00:00<00:00, 372kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 539M/539M [00:01<00:00, 316MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████| 531/531 [00:00<00:00, 317kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|███| 996k/996k [00:00<00:00, 96.3MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.96M/1.96M [00:00<00:00, 8.59MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████| 112/112 [00:00<00:00, 71.5kB/s]\n",
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder sentence-transformers-onxx/distiluse-base-multilingual-cased-v2/onnx\n",
      "Using framework PyTorch: 1.13.1+cu117\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_2 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_3 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_4 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_5 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_6 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_7 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n",
      "model file is saved to  sentence-transformers-onxx/distiluse-base-multilingual-cased-v2/onnx/distiluse-base-multilingual-cased-v2.onnx\n",
      "zip file is saved to  sentence-transformers-onxx/distiluse-base-multilingual-cased-v2/distiluse-base-multilingual-cased-v2.zip \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Case I: Initiate SentenceTransformerModel and Call save_as_onnx\n",
    "\n",
    "# pre_trained_model = SentenceTransformerModel(model_id=model_id, folder_path=folder_path, overwrite=True)\n",
    "# model_path_onnx = pre_trained_model.save_as_onnx(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae1109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Case II: Repeat what save_as_onnx function does\n",
    "\n",
    "# from transformers.convert_graph_to_onnx import convert\n",
    "# from pathlib import Path\n",
    "\n",
    "# model = SentenceTransformer(model_id)\n",
    "# folder_path='sentence-transformers-onxx/distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "# model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "\n",
    "# model_path = os.path.join(folder_path, \"onnx\", model_name)\n",
    "        \n",
    "# convert(\n",
    "#     framework=\"pt\",\n",
    "#     model=model_id,\n",
    "#     output=Path(model_path),\n",
    "#     opset=15,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c474d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Case III: Already run demo_tracing_model_torch_script_onnx_dense notebook \n",
    "\n",
    "# Skip to next step since we already have .onnx at model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8e004",
   "metadata": {},
   "source": [
    "## Creating an ONNX Inference Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72e10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "\n",
    "# Constants from the performance optimization available in onnxruntime\n",
    "# It needs to be done before importing onnxruntime\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "from onnxruntime import InferenceSession, SessionOptions, get_all_providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d3b848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa80c4d",
   "metadata": {},
   "source": [
    "## Initialize pooling function to convert model sequence outputs to pooled outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08444ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# def cls_pooling(model_output, attention_mask):\n",
    "#     return model_output[0][:,0]\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    model_output = torch.from_numpy(model_output[0])\n",
    "    token_embeddings = model_output #First element of model_output contains all token embeddings\n",
    "    attention_mask = torch.from_numpy(attention_mask)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask #, input_mask_expanded, sum_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd18a1",
   "metadata": {},
   "source": [
    "## Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "763f1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\", \"very very long random sentence for testing\"]\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "auto_features = autotokenizer(\n",
    "            input_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7de10b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='sentence-transformers/distiluse-base-multilingual-cased-v2', vocab_size=119547, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autotokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00aef0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b0d42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {k: v.cpu().detach().numpy() for k, v in auto_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127e742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc4bdf",
   "metadata": {},
   "source": [
    "# Get model embedding outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ed70ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0d42ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37953554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b73efeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9, 768)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c81ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_embeddings = mean_pooling(ort_outs, ort_inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b174db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1320,  0.0142,  0.1433,  ..., -0.0988,  0.0680, -0.0085],\n",
       "        [-0.0686,  0.0620,  0.0606,  ..., -0.0303,  0.0438, -0.0155],\n",
       "        [-0.0180, -0.0203,  0.0263,  ...,  0.0434,  0.0379,  0.0609]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea4dea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intermediate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e63e4c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_embeddings[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc6be3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3203e-01,  1.4189e-02,  1.4332e-01,  2.1492e-02, -5.9820e-02,\n",
       "        -8.6129e-02, -1.8077e-01, -2.0854e-02, -8.5716e-03,  9.3090e-02,\n",
       "        -1.1219e-01, -1.0462e-01,  1.0459e-01,  1.0192e-01, -7.2701e-02,\n",
       "         3.8279e-02,  8.7345e-02,  1.0205e-01, -2.1158e-02,  3.7020e-02,\n",
       "        -7.8975e-02,  5.7269e-02, -9.3101e-02,  7.7821e-02,  1.2747e-01,\n",
       "        -6.2213e-02, -1.9867e-02,  1.1089e-02,  4.6685e-02, -9.2737e-02,\n",
       "         5.6247e-02, -8.1862e-02,  4.7888e-02,  5.7801e-03,  2.1205e-02,\n",
       "        -6.7854e-03, -2.9559e-02,  7.7260e-02,  1.5944e-02,  1.1960e-01,\n",
       "        -5.7907e-03, -3.2759e-02,  6.6717e-02,  9.7194e-02, -3.3541e-02,\n",
       "         9.4459e-02, -1.6428e-02,  4.2112e-02, -2.7776e-02, -1.1537e-01,\n",
       "         1.5754e-02,  3.9559e-03, -4.7661e-02,  7.5460e-02, -8.5082e-02,\n",
       "        -3.3376e-02, -3.6117e-03,  1.0537e-01, -7.6681e-02,  3.6040e-02,\n",
       "        -5.4378e-02, -7.9316e-03, -8.1346e-02,  5.9338e-03,  7.3633e-02,\n",
       "         4.7098e-02,  5.8577e-02,  1.1896e-02,  2.1281e-02, -1.9628e-03,\n",
       "        -5.5590e-02,  3.9699e-02,  6.0134e-02, -1.0708e-01,  1.9606e-01,\n",
       "        -4.2684e-02, -2.2421e-03,  8.3857e-02,  3.1168e-03,  4.9722e-02,\n",
       "        -5.4507e-02, -8.6158e-02,  6.1518e-03, -6.5660e-03,  3.6218e-02,\n",
       "        -4.5071e-02, -1.2517e-01, -2.1826e-01, -4.6071e-02,  4.2809e-02,\n",
       "        -1.7502e-01, -4.8833e-03, -2.1071e-01,  1.2823e-01,  6.4700e-03,\n",
       "        -6.1270e-02, -2.8397e-02,  2.3806e-03, -5.0243e-02, -2.1321e-02,\n",
       "        -4.3339e-02,  9.5679e-02, -4.1156e-02,  3.2902e-02,  9.9620e-02,\n",
       "         1.7853e-02,  6.8469e-02, -3.0679e-02, -1.1150e-01,  2.3915e-02,\n",
       "         1.5918e-01,  8.3040e-02,  1.9584e-02, -7.5264e-03, -1.1711e-02,\n",
       "        -1.6652e-02, -9.9848e-02, -1.3008e-01,  1.5448e-01, -1.4007e-01,\n",
       "         5.5047e-02,  1.2755e-01, -4.6418e-03,  3.2977e-02, -3.5971e-03,\n",
       "         4.4954e-02, -1.4354e-02, -1.2561e-01,  8.8523e-02,  1.1051e-02,\n",
       "        -4.2751e-03,  7.9433e-02,  2.1101e-02,  9.3001e-02,  1.8155e-02,\n",
       "        -6.8025e-02,  9.7243e-02, -7.2904e-02, -1.6770e-02, -2.5054e-02,\n",
       "         1.2337e-01,  4.7392e-02, -3.7164e-03,  7.4155e-02, -1.5229e-01,\n",
       "         2.3534e-02, -1.5687e-01,  6.2952e-02, -5.1969e-03, -1.4818e-01,\n",
       "        -8.9390e-02,  3.9442e-02,  4.3356e-04,  7.4718e-02,  3.0458e-03,\n",
       "        -2.1049e-02, -1.3280e-01, -6.3869e-03,  6.6903e-02, -6.3440e-02,\n",
       "         7.2583e-04, -9.8969e-02, -2.1667e-02,  2.2040e-02,  5.2756e-02,\n",
       "        -4.5677e-02,  6.7396e-02,  9.5174e-02,  5.3099e-02, -2.9411e-02,\n",
       "         4.4785e-02,  1.0783e-01,  4.0070e-02,  5.3506e-03, -3.2031e-02,\n",
       "         1.9761e-02,  5.1210e-02, -7.6473e-02,  1.6109e-02, -7.3823e-03,\n",
       "        -1.4913e-01,  8.3672e-02, -1.0254e-01,  5.3154e-02, -1.2539e-01,\n",
       "         5.5491e-02, -6.5997e-02,  2.4484e-02,  1.1016e-02, -8.2491e-02,\n",
       "         2.4532e-02,  4.4697e-02, -5.9843e-02, -9.1062e-02,  1.2788e-02,\n",
       "        -8.0127e-03,  1.7051e-01,  1.7978e-02, -1.0192e-01, -1.6352e-01,\n",
       "        -9.6156e-02, -4.9852e-02,  2.5019e-02, -4.3275e-02, -6.4455e-02,\n",
       "        -1.5734e-02,  1.4902e-01,  3.8161e-02,  1.1201e-01,  4.1133e-02,\n",
       "         5.3304e-02,  1.7228e-02,  3.1371e-02,  2.3496e-02, -2.2454e-03,\n",
       "        -1.8060e-01, -7.2896e-02, -3.4801e-02,  8.7309e-02,  1.1967e-02,\n",
       "        -7.8147e-02, -1.1757e-02,  5.2002e-02,  6.5427e-02, -6.8162e-02,\n",
       "        -5.2689e-02,  1.0622e-02,  1.2506e-02,  3.7537e-02,  6.9273e-03,\n",
       "         1.1132e-01,  4.3350e-02,  1.2578e-01, -4.4076e-02, -9.8296e-02,\n",
       "         2.1239e-02, -1.0420e-01, -2.1360e-02,  7.8574e-02, -9.0408e-02,\n",
       "         4.9508e-03,  5.8672e-02,  3.1244e-02,  1.2348e-01,  5.7820e-02,\n",
       "        -3.9122e-02, -8.3579e-02, -7.2570e-02,  8.2290e-02, -2.9815e-02,\n",
       "        -2.2692e-02,  1.8227e-02,  1.4381e-01,  3.0482e-02,  1.3258e-01,\n",
       "         2.0966e-02, -6.2463e-02,  7.5500e-03, -7.6222e-02, -5.1587e-02,\n",
       "        -6.6580e-02, -1.4276e-02, -2.0168e-01,  6.2477e-02,  1.2704e-02,\n",
       "         1.8915e-02, -1.5601e-02,  8.1896e-02,  2.2966e-02,  1.1809e-01,\n",
       "        -1.0817e-02,  5.6083e-03,  1.5504e-01,  6.7011e-03,  3.6438e-02,\n",
       "        -5.9542e-02, -7.1259e-02,  8.6003e-02,  1.7464e-02, -2.2492e-02,\n",
       "         5.3049e-02,  4.5090e-03,  2.4357e-02, -4.6290e-02, -2.4603e-01,\n",
       "         2.3104e-02, -7.7102e-05,  5.6771e-03,  1.0103e-01,  5.9759e-02,\n",
       "         2.1624e-02, -9.8910e-02,  1.2524e-02, -3.4181e-02, -3.4453e-02,\n",
       "        -4.0979e-02,  3.6747e-02, -4.1519e-02, -2.7106e-02,  9.0293e-02,\n",
       "        -2.1345e-03,  2.6231e-02,  3.2302e-02,  2.1771e-01, -6.4073e-02,\n",
       "        -1.1269e-01, -7.3488e-02, -7.2957e-02, -7.0396e-02, -8.7508e-02,\n",
       "        -7.4768e-02, -8.3213e-02, -7.5804e-02,  7.6602e-02,  7.6855e-02,\n",
       "         1.9287e-01,  8.3513e-02, -1.3595e-02,  7.6850e-02, -2.0009e-02,\n",
       "        -1.0461e-01, -4.0288e-03, -1.0544e-02,  8.3175e-02,  1.2648e-01,\n",
       "        -1.0768e-02, -3.2299e-02, -3.3339e-02, -2.3468e-02,  4.2946e-02,\n",
       "        -1.3287e-01,  1.3308e-02,  3.1820e-02,  2.8541e-02, -6.6753e-02,\n",
       "         5.0725e-02,  3.7491e-02, -5.8745e-03, -1.9753e-01, -9.8915e-02,\n",
       "        -2.9663e-02, -3.9525e-02, -6.5440e-02, -4.5246e-02,  3.4757e-02,\n",
       "        -5.7433e-02,  2.4714e-02, -5.7658e-02,  7.9665e-02,  1.3367e-02,\n",
       "         1.1095e-01, -2.3424e-03,  6.1116e-02,  7.5942e-02, -1.3956e-01,\n",
       "        -4.7216e-02,  2.7957e-02,  6.0388e-02, -9.9000e-02, -6.9101e-02,\n",
       "        -1.3293e-02, -8.3909e-02, -6.9765e-02, -6.2089e-04, -7.6315e-02,\n",
       "        -2.2390e-02,  1.3216e-01, -1.7471e-02,  2.7844e-02,  5.1979e-02,\n",
       "         5.8780e-02, -2.7276e-02,  1.3101e-03,  5.7277e-02,  8.6499e-02,\n",
       "         7.8086e-02,  2.1302e-01, -1.8623e-02, -5.8726e-03,  2.8963e-02,\n",
       "        -1.5827e-03, -1.1925e-02,  1.7840e-02,  3.2090e-02,  2.3928e-03,\n",
       "        -4.0984e-02,  4.4024e-02,  6.4700e-02, -1.0901e-01,  3.8223e-02,\n",
       "         5.3353e-02,  7.1546e-02,  1.6595e-01,  8.5453e-02,  9.1723e-02,\n",
       "        -1.6996e-01,  8.1345e-02, -1.5661e-02, -1.8889e-01, -3.2229e-02,\n",
       "        -5.3432e-02,  4.3002e-03, -9.2740e-03, -2.2004e-02,  9.5658e-03,\n",
       "        -6.7473e-02,  2.7042e-02, -1.8178e-02, -1.7871e-02, -1.2030e-01,\n",
       "         1.1494e-01, -4.3260e-02, -1.1722e-02,  3.1536e-02,  3.7165e-03,\n",
       "         1.8708e-01,  9.5387e-03,  6.4003e-02, -5.6034e-02,  5.4452e-02,\n",
       "        -9.6660e-02, -2.7902e-02,  1.2077e-01,  8.8287e-02, -5.4074e-02,\n",
       "         2.3403e-03,  1.3947e-01,  7.5018e-02, -2.0225e-01, -1.3544e-02,\n",
       "        -4.9653e-02, -4.5057e-02, -7.5141e-02,  9.2784e-03,  1.4573e-01,\n",
       "         3.6887e-02, -4.9973e-02, -8.3864e-02, -1.1910e-01, -2.1585e-02,\n",
       "        -4.6552e-02,  1.4109e-01,  1.0627e-02, -3.8447e-02,  2.5688e-02,\n",
       "         1.4668e-01, -4.9804e-02, -2.9105e-02,  5.7977e-02, -5.4305e-02,\n",
       "        -9.0719e-02, -3.8407e-03, -8.5586e-02,  5.1494e-02, -5.3784e-02,\n",
       "         2.1482e-02,  8.4543e-03,  2.2751e-02, -2.2437e-02,  1.1882e-01,\n",
       "         1.7073e-01,  7.2147e-02, -5.3620e-02, -7.3068e-02, -4.3134e-02,\n",
       "         8.2300e-03, -5.4706e-02,  5.3191e-02,  7.3684e-02,  5.2762e-02,\n",
       "         1.4770e-01,  1.0579e-01,  7.4526e-02, -5.3647e-02,  1.3467e-02,\n",
       "        -4.4325e-02,  5.0269e-02,  1.0545e-02,  2.6240e-02,  3.0584e-02,\n",
       "        -2.9928e-02,  3.0362e-02,  1.2230e-01, -9.2391e-02,  2.0204e-03,\n",
       "        -1.7599e-02, -1.1607e-01,  1.1972e-02,  4.7843e-02,  4.6345e-02,\n",
       "        -4.5010e-04, -1.2495e-02, -9.1458e-02,  5.9264e-02,  2.0258e-02,\n",
       "         6.2087e-02, -8.5119e-02,  1.3946e-01, -4.3921e-02,  9.1528e-02,\n",
       "         1.7482e-01,  5.1736e-02, -1.4428e-02,  1.5706e-01,  1.2678e-01,\n",
       "        -9.3075e-03,  1.7797e-02, -1.5370e-01, -2.5163e-02,  1.1382e-02,\n",
       "         8.2123e-03,  1.2046e-01,  1.7266e-02,  2.6505e-02, -5.8150e-02,\n",
       "         6.7250e-02, -4.1558e-02, -3.3939e-02,  4.3254e-02,  3.5997e-02,\n",
       "        -8.0766e-02, -1.1826e-01,  2.6600e-02, -1.1937e-02, -9.1142e-02,\n",
       "        -1.4495e-02, -1.7820e-02, -1.0150e-01,  3.1803e-02, -1.0099e-02,\n",
       "        -6.5796e-02, -1.2704e-02, -9.1613e-04,  1.0104e-03, -2.7053e-02,\n",
       "         7.0699e-02, -2.2581e-02, -1.2169e-01,  5.2349e-03,  1.1171e-01,\n",
       "        -7.4684e-03, -6.8213e-02, -1.0351e-02,  4.4957e-02,  1.6387e-02,\n",
       "         2.5878e-02, -8.2537e-02, -5.0833e-03, -7.7960e-02, -8.2120e-02,\n",
       "        -3.7216e-02, -2.9085e-02, -6.6148e-02,  1.1530e-01, -9.0687e-02,\n",
       "         1.2387e-01, -7.3895e-02,  1.8204e-03,  6.7968e-02, -7.1930e-02,\n",
       "         9.5651e-02, -3.7486e-02, -4.1079e-02, -2.2520e-02,  3.2346e-02,\n",
       "         2.4665e-02, -6.6960e-02,  4.2942e-02, -1.9446e-02, -1.0239e-01,\n",
       "         3.6415e-02,  4.4383e-03, -4.3737e-02,  1.5879e-02, -1.0608e-01,\n",
       "         1.0036e-01,  4.2115e-02,  2.1359e-02, -1.3324e-01, -7.4771e-02,\n",
       "        -4.9051e-02,  5.6277e-02,  9.0401e-02, -3.3771e-02,  2.0330e-01,\n",
       "         1.0825e-02, -3.8341e-03,  7.4130e-02, -1.5435e-01, -6.7019e-02,\n",
       "        -3.4455e-02, -4.1215e-02, -4.8945e-02, -4.9233e-02, -2.2445e-02,\n",
       "         5.0952e-02,  4.4656e-02, -1.0760e-01, -1.2007e-01, -7.1100e-02,\n",
       "        -1.6196e-02,  5.7529e-02, -2.4949e-02, -9.0361e-02,  1.2647e-02,\n",
       "         9.3830e-03, -1.3475e-01, -6.5586e-02, -2.3593e-02, -1.0969e-03,\n",
       "        -7.0443e-02, -1.8424e-02, -1.7526e-02, -3.1969e-02, -7.0937e-02,\n",
       "        -6.7241e-02, -1.4296e-01, -1.6668e-02, -5.3186e-02, -8.4710e-02,\n",
       "         1.3483e-01,  6.5019e-02, -4.5808e-02,  7.6042e-02,  7.4705e-02,\n",
       "         7.3695e-02,  7.9880e-02, -3.9934e-02,  2.8043e-02, -6.7301e-02,\n",
       "        -9.1955e-02, -1.8366e-02,  8.4614e-02,  5.3117e-02, -1.6017e-01,\n",
       "        -1.0560e-01,  1.7918e-02, -2.6345e-02, -7.4140e-02, -6.9934e-02,\n",
       "        -8.5545e-02,  5.7618e-02, -2.0249e-01,  1.0661e-01,  7.5151e-02,\n",
       "         1.6155e-02,  2.9669e-02, -2.7366e-02, -1.8002e-01, -1.9929e-01,\n",
       "         1.6619e-01, -2.1353e-03, -9.3967e-02, -1.3383e-01,  1.6216e-01,\n",
       "         6.3131e-02,  1.8935e-02, -5.1073e-02,  1.0820e-01,  3.5767e-02,\n",
       "        -2.3434e-02, -1.7013e-02, -1.1480e-01, -2.0621e-02,  1.1476e-02,\n",
       "         1.7288e-01,  8.2910e-02,  4.5204e-02, -4.5071e-02,  4.7116e-02,\n",
       "        -1.8138e-01, -8.2949e-02, -2.4983e-02, -4.2572e-02,  1.0173e-01,\n",
       "         3.5221e-03,  1.3736e-01,  2.5677e-02,  1.7111e-01, -7.4586e-02,\n",
       "         5.1069e-02, -1.4409e-02, -1.5589e-03,  7.1687e-02, -3.5179e-02,\n",
       "         8.9668e-02, -3.6687e-02, -9.0462e-03,  6.0182e-02, -1.3382e-02,\n",
       "        -4.3216e-02, -1.1257e-02,  8.5312e-02,  1.2753e-02,  1.8470e-02,\n",
       "        -1.1774e-01,  4.6079e-02, -6.8204e-02, -4.6618e-02,  1.7638e-02,\n",
       "         3.8755e-02,  1.4147e-03,  4.5997e-02,  1.0347e-01, -1.1635e-01,\n",
       "        -1.3182e-01, -2.0607e-02,  1.0828e-01,  2.1326e-02,  1.4182e-01,\n",
       "        -6.3339e-03, -1.7046e-02, -4.8013e-02, -4.4137e-04,  9.8835e-02,\n",
       "         5.3534e-04, -1.3869e-02,  2.6019e-02,  6.5434e-02,  5.3967e-02,\n",
       "         1.7159e-02,  3.0331e-02, -1.6237e-02,  4.7791e-03, -7.2998e-02,\n",
       "         9.1632e-02, -8.0038e-03,  6.2800e-02, -2.1984e-02,  2.3464e-02,\n",
       "         1.1984e-01, -1.9367e-01,  6.4120e-02, -2.2969e-02,  1.0793e-02,\n",
       "         2.1962e-02,  1.2112e-01,  2.9423e-03,  3.0265e-02,  4.5446e-02,\n",
       "        -1.2215e-01,  1.8323e-02,  5.0564e-02,  1.2442e-03, -1.7107e-01,\n",
       "        -4.6891e-02, -9.4930e-02,  5.1816e-02,  7.7475e-02, -7.5909e-03,\n",
       "         3.6999e-02, -1.7083e-01, -5.1197e-02, -1.2324e-01,  8.4801e-02,\n",
       "         9.8151e-02,  1.2818e-01, -1.1741e-02, -1.4202e-01,  4.4032e-02,\n",
       "         6.2453e-02,  1.5766e-02,  6.2819e-02, -9.6436e-03, -1.3858e-01,\n",
       "        -9.8826e-02,  6.8045e-02, -8.5329e-03])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb437d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def my_dense_layer(intermediate_embeddings, in_features, out_features, bias, activation_func):\n",
    "    linear_func = nn.Linear(in_features, out_features, bias=bias)\n",
    "    sentence_embedding = activation_func(linear_func(intermediate_embeddings))\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8b00752",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "958cbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"in_features\": 768, \"out_features\": 512, \"bias\": true, \"activation_function\": \"torch.nn.modules.activation.Tanh\"}\n",
    "sentence_embeddings = my_dense_layer(intermediate_embeddings, 768, 512, True, activation_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50b5a9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e03f62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe53a",
   "metadata": {},
   "source": [
    "## Verify Embedidngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2e0598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = SentenceTransformer(model_id) # From Huggingface\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "355e6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_onnx = [\n",
    "            sentence_embeddings[i].cpu().detach().numpy()\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8de2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 0.23659697\nMax relative difference: 360.91922\n x: array([ 2.924565e-02,  6.141233e-02, -4.720755e-02,  7.542610e-02,\n       -1.127940e-02, -2.926224e-02, -9.203134e-04,  7.731898e-03,\n        9.389913e-03, -5.170760e-02,  1.561495e-02, -1.805861e-02,...\n y: array([-7.064316e-02, -8.215571e-03, -7.865465e-02,  9.385258e-02,\n       -3.384552e-02, -2.568348e-02, -1.472403e-02,  1.271165e-02,\n       -1.272434e-01,  2.143593e-02, -3.877740e-02, -1.124453e-01,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_sentences)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_embedding_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_data_onnx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 0.23659697\nMax relative difference: 360.91922\n x: array([ 2.924565e-02,  6.141233e-02, -4.720755e-02,  7.542610e-02,\n       -1.127940e-02, -2.926224e-02, -9.203134e-04,  7.731898e-03,\n        9.389913e-03, -5.170760e-02,  1.561495e-02, -1.805861e-02,...\n y: array([-7.064316e-02, -8.215571e-03, -7.865465e-02,  9.385258e-02,\n       -3.384552e-02, -2.568348e-02, -1.472403e-02,  1.271165e-02,\n       -1.272434e-01,  2.143593e-02, -3.877740e-02, -1.124453e-01,..."
     ]
    }
   ],
   "source": [
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1be49f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b364fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.models import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41811e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = Dense(768, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b3e71ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_embedding': tensor([[ 0.0488,  0.0400, -0.0102,  ...,  0.0047, -0.0151,  0.0428],\n",
       "         [ 0.0909, -0.0186, -0.0149,  ...,  0.0123, -0.0201,  0.0643],\n",
       "         [ 0.1176,  0.0234, -0.0471,  ..., -0.0152,  0.0131,  0.0464]],\n",
       "        grad_fn=<TanhBackward0>)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_out = {'sentence_embedding':intermediate_embeddings}\n",
    "dense_layer.forward(feature_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d4b7243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_embedding': tensor([[ 0.0488,  0.0400, -0.0102,  ...,  0.0047, -0.0151,  0.0428],\n",
       "         [ 0.0909, -0.0186, -0.0149,  ...,  0.0123, -0.0201,  0.0643],\n",
       "         [ 0.1176,  0.0234, -0.0471,  ..., -0.0152,  0.0131,  0.0464]],\n",
       "        grad_fn=<TanhBackward0>)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21f5e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_onnx_dense = [\n",
    "            feature_out['sentence_embedding'][i].cpu().detach().numpy()\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c248d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 511 / 512 (99.8%)\nMax absolute difference: 0.2221277\nMax relative difference: 516.7122\n x: array([ 4.880410e-02,  3.999550e-02, -1.015490e-02, -4.416445e-02,\n       -6.098824e-02,  2.730919e-02, -2.198596e-02, -5.392851e-02,\n       -1.930884e-02, -1.697238e-02,  5.076087e-02,  1.768776e-02,...\n y: array([-7.064316e-02, -8.215571e-03, -7.865465e-02,  9.385258e-02,\n       -3.384552e-02, -2.568348e-02, -1.472403e-02,  1.271165e-02,\n       -1.272434e-01,  2.143593e-02, -3.877740e-02, -1.124453e-01,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_sentences)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_data_onnx_dense\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_data_onnx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 511 / 512 (99.8%)\nMax absolute difference: 0.2221277\nMax relative difference: 516.7122\n x: array([ 4.880410e-02,  3.999550e-02, -1.015490e-02, -4.416445e-02,\n       -6.098824e-02,  2.730919e-02, -2.198596e-02, -5.392851e-02,\n       -1.930884e-02, -1.697238e-02,  5.076087e-02,  1.768776e-02,...\n y: array([-7.064316e-02, -8.215571e-03, -7.865465e-02,  9.385258e-02,\n       -3.384552e-02, -2.568348e-02, -1.472403e-02,  1.271165e-02,\n       -1.272434e-01,  2.143593e-02, -3.877740e-02, -1.124453e-01,..."
     ]
    }
   ],
   "source": [
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(embedding_data_onnx_dense[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4c9ab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 0.24952845\nMax relative difference: 1191.9329\n x: array([ 4.880410e-02,  3.999550e-02, -1.015490e-02, -4.416445e-02,\n       -6.098824e-02,  2.730919e-02, -2.198596e-02, -5.392851e-02,\n       -1.930884e-02, -1.697238e-02,  5.076087e-02,  1.768776e-02,...\n y: array([ 2.924565e-02,  6.141233e-02, -4.720755e-02,  7.542610e-02,\n       -1.127940e-02, -2.926224e-02, -9.203134e-04,  7.731898e-03,\n        9.389913e-03, -5.170760e-02,  1.561495e-02, -1.805861e-02,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_sentences)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_data_onnx_dense\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_embedding_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 0.24952845\nMax relative difference: 1191.9329\n x: array([ 4.880410e-02,  3.999550e-02, -1.015490e-02, -4.416445e-02,\n       -6.098824e-02,  2.730919e-02, -2.198596e-02, -5.392851e-02,\n       -1.930884e-02, -1.697238e-02,  5.076087e-02,  1.768776e-02,...\n y: array([ 2.924565e-02,  6.141233e-02, -4.720755e-02,  7.542610e-02,\n       -1.127940e-02, -2.926224e-02, -9.203134e-04,  7.731898e-03,\n        9.389913e-03, -5.170760e-02,  1.561495e-02, -1.805861e-02,..."
     ]
    }
   ],
   "source": [
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(embedding_data_onnx_dense[i], original_embedding_data[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d97b853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66e92537",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = {\n",
    "    'input_ids':  torch.from_numpy(ort_inputs['input_ids']),\n",
    "    'attention_mask':  torch.from_numpy(ort_inputs['attention_mask']),\n",
    "    'token_embeddings': torch.from_numpy(ort_outs[0])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a29d35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.models import Pooling\n",
    "pooling_layer = Pooling(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "226a3e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "         [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "         [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'token_embeddings': tensor([[[-1.8313e-01,  1.6266e-02,  1.4183e-01,  ..., -1.4128e-01,\n",
       "            1.0959e-01, -3.3882e-02],\n",
       "          [-2.0680e-01, -7.3514e-04,  2.7081e-01,  ..., -1.0606e-01,\n",
       "            6.6462e-02,  3.1641e-02],\n",
       "          [-1.2847e-01,  5.6789e-02,  1.0754e-01,  ..., -4.9264e-02,\n",
       "            1.1284e-01, -5.2882e-02],\n",
       "          ...,\n",
       "          [-1.4783e-01, -4.6210e-02,  1.8090e-02,  ..., -1.6317e-01,\n",
       "            1.6244e-01,  6.5027e-02],\n",
       "          [-4.3051e-03,  5.6201e-02,  2.1051e-02,  ..., -1.8682e-01,\n",
       "            1.6163e-01,  5.4055e-02],\n",
       "          [-6.2831e-02,  2.9120e-02, -1.0469e-03,  ..., -1.3042e-01,\n",
       "            1.8227e-01,  3.8073e-02]],\n",
       " \n",
       "         [[-1.1220e-01,  5.9799e-02,  6.7730e-02,  ..., -4.9089e-02,\n",
       "            9.2361e-02, -2.8891e-02],\n",
       "          [-1.0913e-01,  9.9684e-02,  1.1172e-01,  ..., -1.7982e-02,\n",
       "            2.0708e-02, -1.8689e-02],\n",
       "          [-6.5157e-02,  8.9817e-02,  3.9802e-02,  ...,  2.1830e-02,\n",
       "            8.8468e-02, -4.7001e-02],\n",
       "          ...,\n",
       "          [-9.1025e-02,  2.3052e-04, -1.4382e-02,  ..., -1.2492e-01,\n",
       "            1.3426e-01,  5.5879e-02],\n",
       "          [ 3.7318e-02,  8.8343e-02, -2.9605e-03,  ..., -1.4787e-01,\n",
       "            1.4283e-01,  4.9930e-02],\n",
       "          [-2.7284e-02,  5.3074e-02, -3.8296e-02,  ..., -8.8513e-02,\n",
       "            1.4540e-01,  3.9877e-02]],\n",
       " \n",
       "         [[-1.2353e-01, -1.2354e-01, -5.0822e-03,  ...,  3.5122e-02,\n",
       "            3.9395e-02,  3.7612e-02],\n",
       "          [ 1.5276e-02, -8.4679e-03,  6.7582e-02,  ..., -1.3885e-02,\n",
       "            9.2690e-02,  5.4737e-02],\n",
       "          [ 2.2147e-02,  6.4932e-03,  4.2993e-02,  ..., -2.9343e-02,\n",
       "            6.7385e-02,  5.3883e-02],\n",
       "          ...,\n",
       "          [-6.9876e-02, -9.5855e-02,  6.3308e-02,  ...,  3.4906e-02,\n",
       "           -1.1012e-03,  1.2743e-01],\n",
       "          [ 1.1409e-02, -4.8537e-02, -3.9122e-03,  ...,  1.1344e-01,\n",
       "            1.0512e-01,  5.4397e-02],\n",
       "          [-9.4931e-03, -8.8494e-03,  3.6188e-02,  ..., -3.8251e-03,\n",
       "           -1.8624e-02,  1.5673e-02]]]),\n",
       " 'sentence_embedding': tensor([[-0.1320,  0.0142,  0.1433,  ..., -0.0988,  0.0680, -0.0085],\n",
       "         [-0.0686,  0.0620,  0.0606,  ..., -0.0303,  0.0438, -0.0155],\n",
       "         [-0.0180, -0.0203,  0.0263,  ...,  0.0434,  0.0379,  0.0609]])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_layer.forward(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f3c639b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "         [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "         [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'token_embeddings': tensor([[[-1.8313e-01,  1.6266e-02,  1.4183e-01,  ..., -1.4128e-01,\n",
       "            1.0959e-01, -3.3882e-02],\n",
       "          [-2.0680e-01, -7.3514e-04,  2.7081e-01,  ..., -1.0606e-01,\n",
       "            6.6462e-02,  3.1641e-02],\n",
       "          [-1.2847e-01,  5.6789e-02,  1.0754e-01,  ..., -4.9264e-02,\n",
       "            1.1284e-01, -5.2882e-02],\n",
       "          ...,\n",
       "          [-1.4783e-01, -4.6210e-02,  1.8090e-02,  ..., -1.6317e-01,\n",
       "            1.6244e-01,  6.5027e-02],\n",
       "          [-4.3051e-03,  5.6201e-02,  2.1051e-02,  ..., -1.8682e-01,\n",
       "            1.6163e-01,  5.4055e-02],\n",
       "          [-6.2831e-02,  2.9120e-02, -1.0469e-03,  ..., -1.3042e-01,\n",
       "            1.8227e-01,  3.8073e-02]],\n",
       " \n",
       "         [[-1.1220e-01,  5.9799e-02,  6.7730e-02,  ..., -4.9089e-02,\n",
       "            9.2361e-02, -2.8891e-02],\n",
       "          [-1.0913e-01,  9.9684e-02,  1.1172e-01,  ..., -1.7982e-02,\n",
       "            2.0708e-02, -1.8689e-02],\n",
       "          [-6.5157e-02,  8.9817e-02,  3.9802e-02,  ...,  2.1830e-02,\n",
       "            8.8468e-02, -4.7001e-02],\n",
       "          ...,\n",
       "          [-9.1025e-02,  2.3052e-04, -1.4382e-02,  ..., -1.2492e-01,\n",
       "            1.3426e-01,  5.5879e-02],\n",
       "          [ 3.7318e-02,  8.8343e-02, -2.9605e-03,  ..., -1.4787e-01,\n",
       "            1.4283e-01,  4.9930e-02],\n",
       "          [-2.7284e-02,  5.3074e-02, -3.8296e-02,  ..., -8.8513e-02,\n",
       "            1.4540e-01,  3.9877e-02]],\n",
       " \n",
       "         [[-1.2353e-01, -1.2354e-01, -5.0822e-03,  ...,  3.5122e-02,\n",
       "            3.9395e-02,  3.7612e-02],\n",
       "          [ 1.5276e-02, -8.4679e-03,  6.7582e-02,  ..., -1.3885e-02,\n",
       "            9.2690e-02,  5.4737e-02],\n",
       "          [ 2.2147e-02,  6.4932e-03,  4.2993e-02,  ..., -2.9343e-02,\n",
       "            6.7385e-02,  5.3883e-02],\n",
       "          ...,\n",
       "          [-6.9876e-02, -9.5855e-02,  6.3308e-02,  ...,  3.4906e-02,\n",
       "           -1.1012e-03,  1.2743e-01],\n",
       "          [ 1.1409e-02, -4.8537e-02, -3.9122e-03,  ...,  1.1344e-01,\n",
       "            1.0512e-01,  5.4397e-02],\n",
       "          [-9.4931e-03, -8.8494e-03,  3.6188e-02,  ..., -3.8251e-03,\n",
       "           -1.8624e-02,  1.5673e-02]]]),\n",
       " 'sentence_embedding': tensor([[ 0.0488,  0.0400, -0.0102,  ...,  0.0047, -0.0151,  0.0428],\n",
       "         [ 0.0909, -0.0186, -0.0149,  ...,  0.0123, -0.0201,  0.0643],\n",
       "         [ 0.1176,  0.0234, -0.0471,  ..., -0.0152,  0.0131,  0.0464]],\n",
       "        grad_fn=<TanhBackward0>)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer.forward(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca13367f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 1536 / 1536 (100%)\nMax absolute difference: 0.24952845\nMax relative difference: 1938.1483\n x: array([[ 0.029246,  0.061412, -0.047208, ..., -0.039461,  0.016063,\n        -0.03649 ],\n       [ 0.004959,  0.037416, -0.027066, ..., -0.030502,  0.031936,...\n y: array([[ 0.048804,  0.039995, -0.010155, ...,  0.00474 , -0.015072,\n         0.042837],\n       [ 0.090853, -0.018568, -0.014919, ...,  0.012304, -0.020059,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_embedding_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence_embedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 1536 / 1536 (100%)\nMax absolute difference: 0.24952845\nMax relative difference: 1938.1483\n x: array([[ 0.029246,  0.061412, -0.047208, ..., -0.039461,  0.016063,\n        -0.03649 ],\n       [ 0.004959,  0.037416, -0.027066, ..., -0.030502,  0.031936,...\n y: array([[ 0.048804,  0.039995, -0.010155, ...,  0.00474 , -0.015072,\n         0.042837],\n       [ 0.090853, -0.018568, -0.014919, ...,  0.012304, -0.020059,..."
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(original_embedding_data, test_features['sentence_embedding'].cpu().detach().numpy(), rtol=1e-03, atol=1e-05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
