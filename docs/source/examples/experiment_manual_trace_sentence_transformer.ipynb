{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f1cd1c",
   "metadata": {},
   "source": [
    "# Trace Sentence Transfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e1e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_id = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
    "model = SentenceTransformer(model_id)\n",
    "device = torch.device(\"cpu\")\n",
    "cpu_model = model.to(device)\n",
    "sentences = ['Sentence 1','Sentence 2']\n",
    "features = cpu_model.tokenizer(\n",
    "            sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        ).to(device)\n",
    "ex_input = {\n",
    "                    \"input_ids\": features[\"input_ids\"],\n",
    "                    \"attention_mask\": features[\"attention_mask\"],\n",
    "                }\n",
    "traced_model = torch.jit.trace(model, ex_input, strict=False)\n",
    "torch.jit.save(traced_model, \"traced_sentence_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67f671a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=SentenceTransformer\n",
       "  (0): RecursiveScriptModule(\n",
       "    original_name=Transformer\n",
       "    (auto_model): RecursiveScriptModule(\n",
       "      original_name=DistilBertModel\n",
       "      (embeddings): RecursiveScriptModule(\n",
       "        original_name=Embeddings\n",
       "        (word_embeddings): RecursiveScriptModule(original_name=Embedding)\n",
       "        (position_embeddings): RecursiveScriptModule(original_name=Embedding)\n",
       "        (LayerNorm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (transformer): RecursiveScriptModule(\n",
       "        original_name=Transformer\n",
       "        (layer): RecursiveScriptModule(\n",
       "          original_name=ModuleList\n",
       "          (0): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (1): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (2): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (3): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (4): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (5): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): RecursiveScriptModule(original_name=Pooling)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = torch.jit.load(\"traced_sentence_transformer.pt\")\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b9ccc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2034, 6251,  102],\n",
       "         [ 101, 2117, 6251,  102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]]),\n",
       " 'token_embeddings': tensor([[[ 0.2192, -0.2669, -0.2511,  ...,  0.0324, -0.3444, -0.0308],\n",
       "          [-0.1659, -0.2614, -0.5352,  ...,  0.2587, -0.1672, -0.2693],\n",
       "          [ 0.3557, -0.1637, -0.1883,  ...,  0.0900, -0.5482, -0.4730],\n",
       "          [ 0.7434, -0.2904,  0.0787,  ...,  0.5496, -0.8846, -0.1438]],\n",
       " \n",
       "         [[-0.0738, -0.4391, -0.0976,  ...,  0.0442, -0.1356, -0.3168],\n",
       "          [ 0.1501, -0.7653, -0.1249,  ...,  0.0637,  0.1336, -0.4225],\n",
       "          [ 0.1538, -0.2468,  0.0779,  ...,  0.1835, -0.3914, -0.5732],\n",
       "          [ 0.6191, -0.3375,  0.3204,  ...,  0.4383, -0.5994, -0.5623]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " 'sentence_embedding': tensor([[ 0.2192, -0.2669, -0.2511,  ...,  0.0324, -0.3444, -0.0308],\n",
       "         [-0.0738, -0.4391, -0.0976,  ...,  0.0442, -0.1356, -0.3168]],\n",
       "        grad_fn=<CatBackward0>)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = [\"first sentence\", \"second sentence\"]\n",
    "features = cpu_model.tokenizer(\n",
    "            test_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        ).to(device)\n",
    "test_input = {\n",
    "                    \"input_ids\": features[\"input_ids\"],\n",
    "                    \"attention_mask\": features[\"attention_mask\"],\n",
    "                }\n",
    "\n",
    "pt_embedding = loaded_model(test_input)\n",
    "pt_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d843511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_embedding['sentence_embedding'].detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974eaa8b",
   "metadata": {},
   "source": [
    "# Compare Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e2fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d31074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21917519, -0.26689667, -0.25107574, ...,  0.03239337,\n",
       "        -0.34440702, -0.03081493],\n",
       "       [-0.07382002, -0.43907577, -0.09760092, ...,  0.04419765,\n",
       "        -0.1355662 , -0.31682503]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_embedding = model.encode(test_sentences, convert_to_numpy=True)\n",
    "original_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62449635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.testing.assert_allclose(original_embedding, pt_embedding['sentence_embedding'].detach().cpu().numpy(), rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12014579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
