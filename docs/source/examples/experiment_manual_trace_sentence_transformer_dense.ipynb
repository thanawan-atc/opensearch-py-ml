{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444e24fd",
   "metadata": {},
   "source": [
    "# Trace Sentence Transfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a9bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69840885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"TracerWarning: torch.tensor\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"using SSL with verify_certs=False is insecure.\")\n",
    "\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel\n",
    "# import mlcommon to later register the model to OpenSearch Cluster\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d550489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# model_id = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
    "# model = SentenceTransformer(model_id)\n",
    "# device = torch.device(\"cpu\")\n",
    "# cpu_model = model.to(device)\n",
    "# sentences = ['Sentence 1','Sentence 2']\n",
    "# features = cpu_model.tokenizer(\n",
    "#             sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "#         ).to(device)\n",
    "# ex_input = {\n",
    "#                     \"input_ids\": features[\"input_ids\"],\n",
    "#                     \"attention_mask\": features[\"attention_mask\"],\n",
    "#                 }\n",
    "# traced_model = torch.jit.trace(model, ex_input, strict=False)\n",
    "# torch.jit.save(traced_model, \"traced_sentence_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11f4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_URL = 'https://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee42b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_client(cluster_url = CLUSTER_URL,\n",
    "                  username='admin',\n",
    "                  password='admin'):\n",
    "    '''\n",
    "    Get OpenSearch client\n",
    "    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443\n",
    "    :return: OpenSearch client\n",
    "    '''\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url],\n",
    "        http_auth=(username, password),\n",
    "        verify_certs=False\n",
    "    )\n",
    "    return client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50ddfbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/opensearchpy/connection/http_urllib3.py:199: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = get_os_client()\n",
    "\n",
    "# Connect to ml_common client with OpenSearch client\n",
    "ml_client = MLCommonClient(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60fc42a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file is saved to  sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/distiluse-base-multilingual-cased-v1.pt\n",
      "zip file is saved to  sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/distiluse-base-multilingual-cased-v1.zip \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_id=\"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "pre_trained_model = SentenceTransformerModel(model_id=model_id, folder_path='sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1', overwrite=True)\n",
    "model_path = pre_trained_model.save_as_pt(model_id=model_id, sentences=[\"for example providing a small sentence\", \"we can add multiple sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f189fa5",
   "metadata": {},
   "source": [
    "# Load Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9d2d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=SentenceTransformer\n",
       "  (0): RecursiveScriptModule(\n",
       "    original_name=Transformer\n",
       "    (auto_model): RecursiveScriptModule(\n",
       "      original_name=DistilBertModel\n",
       "      (embeddings): RecursiveScriptModule(\n",
       "        original_name=Embeddings\n",
       "        (word_embeddings): RecursiveScriptModule(original_name=Embedding)\n",
       "        (position_embeddings): RecursiveScriptModule(original_name=Embedding)\n",
       "        (LayerNorm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (transformer): RecursiveScriptModule(\n",
       "        original_name=Transformer\n",
       "        (layer): RecursiveScriptModule(\n",
       "          original_name=ModuleList\n",
       "          (0): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (1): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (2): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (3): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (4): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "          (5): RecursiveScriptModule(\n",
       "            original_name=TransformerBlock\n",
       "            (attention): RecursiveScriptModule(\n",
       "              original_name=MultiHeadSelfAttention\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (q_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (k_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (v_lin): RecursiveScriptModule(original_name=Linear)\n",
       "              (out_lin): RecursiveScriptModule(original_name=Linear)\n",
       "            )\n",
       "            (sa_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (ffn): RecursiveScriptModule(\n",
       "              original_name=FFN\n",
       "              (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "              (lin1): RecursiveScriptModule(original_name=Linear)\n",
       "              (lin2): RecursiveScriptModule(original_name=Linear)\n",
       "              (activation): RecursiveScriptModule(original_name=GELUActivation)\n",
       "            )\n",
       "            (output_layer_norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): RecursiveScriptModule(original_name=Pooling)\n",
       "  (2): RecursiveScriptModule(\n",
       "    original_name=Dense\n",
       "    (activation_function): RecursiveScriptModule(original_name=Tanh)\n",
       "    (linear): RecursiveScriptModule(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "loaded_model = torch.jit.load(\"sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/distiluse-base-multilingual-cased-v1.pt\")\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07332ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0],\n",
       "         [  101, 11132, 13172, 20165, 49219,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1]]),\n",
       " 'token_embeddings': tensor([[[-0.0932,  0.0432,  0.1432,  ..., -0.1103,  0.0942, -0.0037],\n",
       "          [-0.1012,  0.0241,  0.1627,  ..., -0.0762,  0.0517,  0.0244],\n",
       "          [-0.1129,  0.1023,  0.0799,  ..., -0.0908,  0.1273, -0.0619],\n",
       "          [-0.0190, -0.0165,  0.0428,  ..., -0.0710, -0.0092,  0.0306],\n",
       "          [-0.0025,  0.0387,  0.0554,  ..., -0.0957,  0.1055,  0.0341],\n",
       "          [-0.0489,  0.0154,  0.0672,  ..., -0.1079,  0.1109, -0.0167]],\n",
       " \n",
       "         [[-0.1305,  0.0559,  0.0766,  ..., -0.0346,  0.0872,  0.0860],\n",
       "          [-0.1149,  0.0713,  0.0938,  ..., -0.0121,  0.0341,  0.0632],\n",
       "          [-0.0466,  0.0071,  0.0116,  ..., -0.0323,  0.0609,  0.1089],\n",
       "          [-0.0728,  0.0599,  0.0552,  ..., -0.0520,  0.0804,  0.0945],\n",
       "          [-0.1406,  0.1172, -0.0054,  ..., -0.0232,  0.0887,  0.0162],\n",
       "          [-0.0162,  0.0071,  0.0325,  ..., -0.0483, -0.0158,  0.0468]]],\n",
       "        grad_fn=<DifferentiableGraphBackward>),\n",
       " 'sentence_embedding': tensor([[ 0.0110,  0.0648, -0.0457,  ..., -0.0498,  0.0185, -0.0380],\n",
       "         [ 0.0446,  0.0522,  0.0043,  ..., -0.0779,  0.0626, -0.0057]],\n",
       "        grad_fn=<DifferentiableGraphBackward>)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(model_id)\n",
    "device = torch.device(\"cpu\")\n",
    "cpu_model = model.to(device)\n",
    "\n",
    "test_sentences = [\"first sentence\", \"second much longer sentence\"]\n",
    "features = cpu_model.tokenizer(\n",
    "            test_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        ).to(device)\n",
    "test_input = {\n",
    "                    \"input_ids\": features[\"input_ids\"],\n",
    "                    \"attention_mask\": features[\"attention_mask\"],\n",
    "                }\n",
    "\n",
    "pt_embedding = loaded_model(test_input)\n",
    "pt_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47354eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 512)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_embedding['sentence_embedding'].detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d433b",
   "metadata": {},
   "source": [
    "# Compare Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88637a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98f390d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01097566,  0.06483249, -0.04571173, ..., -0.04982213,\n",
       "         0.01845153, -0.03800954],\n",
       "       [ 0.04462758,  0.05222933,  0.0042971 , ..., -0.07785919,\n",
       "         0.06257077, -0.00566589]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_embedding = model.encode(test_sentences, convert_to_numpy=True)\n",
    "original_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f1437a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.testing.assert_allclose(original_embedding, pt_embedding['sentence_embedding'].detach().cpu().numpy(), rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c48db9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0],\n",
       "        [  101, 11132, 13172, 20165, 49219,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ae42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a753c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96189f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "autotokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "097104cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_features = autotokenizer(\n",
    "            test_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8be9b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0],\n",
       "        [  101, 11132, 13172, 20165, 49219,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d49e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d297900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c3b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa71f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d93302b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "fantasy_zip = zipfile.ZipFile(\"sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/distiluse-base-multilingual-cased-v1.zip\")\n",
    "fantasy_zip.extractall(\"sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/extract\")\n",
    "\n",
    "fantasy_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "638a90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/extract/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc937b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.add_special_tokens({\n",
    "  \"cls_token\": \"[CLS]\",\n",
    "  \"mask_token\": \"[MASK]\",\n",
    "  \"pad_token\": \"[PAD]\",\n",
    "  \"sep_token\": \"[SEP]\",\n",
    "  \"unk_token\": \"[UNK]\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9aee3fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='', vocab_size=119547, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56647ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/new/tokenizer_config.json',\n",
       " 'sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/new/special_tokens_map.json',\n",
       " 'sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/new/tokenizer.json')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.save_pretrained(\"sentence-transformers-torchscript/distiluse-base-multilingual-cased-v1/new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70565991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "fast_features = fast_tokenizer(\n",
    "            test_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f0d245e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0],\n",
       "        [  101, 11132, 13172, 20165, 49219,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f6bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
