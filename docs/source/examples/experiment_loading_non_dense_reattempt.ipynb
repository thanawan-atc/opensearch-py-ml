{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26bec45",
   "metadata": {},
   "source": [
    "# Experiment Notebook\n",
    "Load .onnx and Verify Embedding without ML-Commons API to see if the problem is with ML-Commons API or the .onnx file itself\n",
    "\n",
    "Reference: https://github.com/SidJain1412/sentence-transformers/blob/master/examples/onnx/onnx_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7fcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d30d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"TracerWarning: torch.tensor\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"using SSL with verify_certs=False is insecure.\")\n",
    "\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel\n",
    "# import mlcommon to later register the model to OpenSearch Cluster\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5942be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_URL = 'https://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837bd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_client(cluster_url = CLUSTER_URL,\n",
    "                  username='admin',\n",
    "                  password='admin'):\n",
    "    '''\n",
    "    Get OpenSearch client\n",
    "    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443\n",
    "    :return: OpenSearch client\n",
    "    '''\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url],\n",
    "        http_auth=(username, password),\n",
    "        verify_certs=False\n",
    "    )\n",
    "    return client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9219ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/opensearchpy/connection/http_urllib3.py:199: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = get_os_client()\n",
    "\n",
    "# Connect to ml_common client with OpenSearch client\n",
    "ml_client = MLCommonClient(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b935d5",
   "metadata": {},
   "source": [
    "## Trace the Model in Onnx Using save_as_onnx\n",
    "See `opensearch_py_ml/ml_models/sentencetransformermodel.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9f10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
    "folder_path='sentence-transformers-onxx/msmarco-distilbert-base-tas-b'\n",
    "model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "model_path = os.path.join(folder_path, \"onnx\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f270c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case I: Initiate SentenceTransformerModel and Call save_as_onnx\n",
    "\n",
    "# pre_trained_model = SentenceTransformerModel(model_id=model_id, folder_path=folder_path, overwrite=True)\n",
    "# model_path_onnx = pre_trained_model.save_as_onnx(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case II: Repeat what save_as_onnx function does\n",
    "\n",
    "# from transformers.convert_graph_to_onnx import convert\n",
    "# from pathlib import Path\n",
    "\n",
    "# model = SentenceTransformer(model_id)\n",
    "# folder_path='sentence-transformers-onxx/distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "# model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "\n",
    "# model_path = os.path.join(folder_path, \"onnx\", model_name)\n",
    "        \n",
    "# convert(\n",
    "#     framework=\"pt\",\n",
    "#     model=model_id,\n",
    "#     output=Path(model_path),\n",
    "#     opset=15,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c474d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case III: Already run demo_tracing_model_torch_script_onnx_dense notebook \n",
    "\n",
    "# Skip to next step since we already have .onnx at model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8e004",
   "metadata": {},
   "source": [
    "## Creating an ONNX Inference Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b72e10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "\n",
    "# Constants from the performance optimization available in onnxruntime\n",
    "# It needs to be done before importing onnxruntime\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "from onnxruntime import InferenceSession, SessionOptions, get_all_providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d3b848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa80c4d",
   "metadata": {},
   "source": [
    "## Initialize pooling function to convert model sequence outputs to pooled outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08444ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def cls_pooling(model_output, attention_mask):\n",
    "    return model_output[0][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd18a1",
   "metadata": {},
   "source": [
    "## Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "763f1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\", \"very very long random sentence for testing\"]\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "auto_features = autotokenizer(\n",
    "            input_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7de10b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='sentence-transformers/msmarco-distilbert-base-tas-b', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autotokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00aef0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2034, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2117, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2200, 2200, 2146, 6721, 6251, 2005, 5604,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b0d42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {k: v.cpu().detach().numpy() for k, v in auto_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127e742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[ 101, 2034, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2117, 6251,  102,    0,    0,    0,    0,    0],\n",
       "        [ 101, 2200, 2200, 2146, 6721, 6251, 2005, 5604,  102]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc4bdf",
   "metadata": {},
   "source": [
    "# Get model embedding outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ed70ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0d42ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37953554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b73efeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c81ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = cls_pooling(ort_outs, ort_inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea4dea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21917413, -0.26689678, -0.25107464, ...,  0.03239307,\n",
       "        -0.3444069 , -0.0308149 ],\n",
       "       [-0.07382086, -0.43907598, -0.09760167, ...,  0.04419803,\n",
       "        -0.13556568, -0.31682545],\n",
       "       [ 0.4373184 , -0.61487097, -0.11806443, ...,  0.22158673,\n",
       "        -0.3373356 , -0.07646542]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e63e4c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe53a",
   "metadata": {},
   "source": [
    "## Verify Embedidngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2e0598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = SentenceTransformer(model_id) # From Huggingface\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "355e6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_onnx = [\n",
    "            sentence_embeddings[i]\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8de2d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "None\n",
      "1\n",
      "None\n",
      "2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
