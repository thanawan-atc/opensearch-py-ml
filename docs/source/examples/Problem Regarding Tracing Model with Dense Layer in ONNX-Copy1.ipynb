{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a0804b",
   "metadata": {},
   "source": [
    "# Problems Regarding Tracing Model with Dense Layer in ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e9523",
   "metadata": {},
   "source": [
    "## Background Context\n",
    "\n",
    "We want to trace a pretrained sentence-transformer model into torch_script and onnx to upload it to the artifact server, so that the users can use the following ml-commons API to deploy the model and generate embeddings: `register` -> `deploy` -> `generate_embedding`. \n",
    "\n",
    "```\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient\n",
    "\n",
    "client = get_os_client()\n",
    "ml_client = MLCommonClient(client)\n",
    "\n",
    "model_id = \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "folder_path='sentence-transformers-onxx/distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "pre_trained_model = SentenceTransformerModel(model_id=model_id, folder_path=folder_path, overwrite=True)\n",
    "model_path_onnx = pre_trained_model.save_as_onnx(model_id=model_id)\n",
    "\n",
    "model_config_path_onnx = 'sentence-transformers-onxx/distiluse-base-multilingual-cased-v1/ml-commons_model_config.json'\n",
    "ml_client.register_model(model_path_onnx, model_config_path_onnx, isVerbose=True)\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\"]\n",
    "results = ml_client.generate_embedding(\"hv0c7IkBVsgBeq9g7M_J\", input_sentences)\n",
    "onnx_embedding = [\n",
    "            embedding_output_onnx[\"inference_results\"][i][\"output\"][0][\"data\"]\n",
    "            for i in range(len(input_sentences))\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "This should give the same output with the following Huggingface `encode` calls.\n",
    "```\n",
    "from sentence_transformers import SentenceTransformer\n",
    "input_sentences = [\"first sentence\", \"second sentence\"]\n",
    "\n",
    "huggingface_model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')\n",
    "huggingface_embeddings = huggingface_model.encode(input_sentences)\n",
    "print(huggingface_embeddings)\n",
    "\n",
    "```\n",
    "\n",
    "Note that there is our `SentenceTransformerModel` class and Hugging Face `SentenceTransformer`class.\n",
    "\n",
    "The problem we face is that `onnx_embedding` has shape `(768,)`  while `huggingface_embeddings` has shape `(512,)`. However, we do not face this problem with `torch_script_embedding`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f42762",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "Based on the mismatch in output shape and the model architecture below, the problem is likely because the `Dense` layer is not part of the `onnx` model.\n",
    "\n",
    "```\n",
    "SentenceTransformer(\n",
    "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
    "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
    "  (2): Dense({'in_features': 768, 'out_features': 512, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
    ")\n",
    "```\n",
    "\n",
    "At first, I thought that the problem is with `convert` in `transformers.convert_graph_to_onnx` that we use to trace `onnx` file. However, I realize that for other models that have pooling layer as the last layer, their `onnx` file does not include pooling layer as well. Moreover, [this line of code](https://github.com/opensearch-project/ml-commons/blob/7467a692e3cf3d7cdf2b5db0b21c11e67fcf5621/ml-algorithms/src/main/java/org/opensearch/ml/engine/algorithms/text_embedding/ONNXSentenceTransformerTextEmbeddingTranslator.java#L83C19-L83C32) in ML-Commons shows that `onnx` model relies on post-processing in ML-commons to generate embedding from the model output (See example of how others load and generate embeddings by calling pooling function on model output [here](https://github.com/SidJain1412/sentence-transformers/blob/master/examples/onnx/onnx_example.ipynb)), while `torch_script` does not rely on this. Hence, the problem is we have not applied `dense` function. We should add it in post-processing step as we do for `pooling` and `normalize` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817e186",
   "metadata": {},
   "source": [
    "# Problems\n",
    "\n",
    "Based on above findings, I tried loading `onnx` model and adding pooling and dense layers to its output. But there is still a mistmach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805cb9a",
   "metadata": {},
   "source": [
    "### Case A: Models with Only Pooling — Working fine\n",
    "\n",
    "Below is the overview of the code for tracing models with only pooling layer in `onnx`. This works fine.\n",
    "\n",
    "I. Get Inputs\n",
    "```\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\", \"very very long random sentence for testing\"]\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "auto_features = autotokenizer(\n",
    "            input_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )\n",
    "```\n",
    "\n",
    "II. Load `onnx` model & Generate Ouputs\n",
    "```\n",
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "from onnxruntime import InferenceSession, SessionOptions, get_all_providers\n",
    "\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "\n",
    "ort_session = InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_inputs = {k: v.cpu().detach().numpy() for k, v in auto_features.items()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "```\n",
    "\n",
    "III. Add Pooling Layer to Get Sentence Embeddings\n",
    "```\n",
    "import torch\n",
    "from sentence_transformers.models import Pooling\n",
    "\n",
    "pooling_layer = Pooling(768, pooling_mode_cls_token=True, pooling_mode_mean_tokens=False)\n",
    "features = {\n",
    "    'token_embeddings':  torch.from_numpy(ort_outs[0]),\n",
    "    'attention_mask': torch.from_numpy(ort_inputs['attention_mask'])\n",
    "}\n",
    "pooling_layer.forward(features)\n",
    "sentence_embeddings = features['sentence_embedding']\n",
    "\n",
    "embedding_data_onnx = [\n",
    "            sentence_embeddings[i]\n",
    "            for i in range(len(input_sentences))\n",
    "        ]\n",
    "```\n",
    "\n",
    "IV. Verify Embedding with Embeddings Encoded with Hugging Face Model \n",
    "```\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = SentenceTransformer(model_id) # From Huggingface\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")\n",
    "        \n",
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5ce2f",
   "metadata": {},
   "source": [
    "### Case B: Models with Pooling & Dense — Mismatch Output\n",
    "\n",
    "```\n",
    "SentenceTransformer(\n",
    "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
    "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
    "  (2): Dense({'in_features': 768, 'out_features': 512, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
    ")\n",
    "```\n",
    "https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c0416",
   "metadata": {},
   "source": [
    "#### 0. Trace the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3007e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/transformers/convert_graph_to_onnx.py:379: FutureWarning: The `transformers.convert_graph_to_onnx` package is deprecated and will be removed in version 5 of Transformers\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 15\n",
      "Loading pipeline (model: sentence-transformers/clip-ViT-B-32-multilingual-v1, tokenizer: sentence-transformers/clip-ViT-B-32-multilingual-v1)\n",
      "Creating folder sentence-transformers-onxx/clip-ViT-B-32-multilingual-v1/onnx\n",
      "Using framework PyTorch: 1.13.1+cu117\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers.convert_graph_to_onnx import convert\n",
    "\n",
    "model_id = \"sentence-transformers/clip-ViT-B-32-multilingual-v1\"\n",
    "folder_path='sentence-transformers-onxx/clip-ViT-B-32-multilingual-v12'\n",
    "model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "model_path = os.path.join(folder_path, \"onnx\", model_name)\n",
    "\n",
    "model = SentenceTransformer(model_id)\n",
    "folder_path='sentence-transformers-onxx/clip-ViT-B-32-multilingual-v1'\n",
    "\n",
    "model_name = str(model_id.split(\"/\")[-1] + \".onnx\")\n",
    "\n",
    "model_path = os.path.join(folder_path, \"onnx\", model_name)\n",
    "        \n",
    "convert(\n",
    "    framework=\"pt\",\n",
    "    model=model_id,\n",
    "    output=Path(model_path),\n",
    "    opset=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c974bb",
   "metadata": {},
   "source": [
    "#### I. Get Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22afa595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\", \"very very long random sentence for testing\"]\n",
    "autotokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "auto_features = autotokenizer(\n",
    "            input_sentences, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )\n",
    "auto_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b730a2",
   "metadata": {},
   "source": [
    "II. Load `onnx` model & Generate Ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bcf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "from onnxruntime import InferenceSession, SessionOptions, get_all_providers\n",
    "\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "ort_session = InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_inputs = {k: v.cpu().detach().numpy() for k, v in auto_features.items()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddafcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101, 10422, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 11132, 49219,   102,     0,     0,     0,     0,     0],\n",
       "        [  101, 12558, 12558, 11695, 61952, 49219, 10142, 38306,   102]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c356e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3, 9, 768)\n"
     ]
    }
   ],
   "source": [
    "print(len(ort_outs))\n",
    "print(ort_outs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbedc397",
   "metadata": {},
   "source": [
    "#### III. Add Pooling Layer (Mean Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9abc829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['token_embeddings', 'attention_mask', 'sentence_embedding'])\n",
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers.models import Pooling\n",
    "\n",
    "pooling_layer = Pooling(768, pooling_mode_mean_tokens=True)\n",
    "features = {\n",
    "    'token_embeddings':  torch.from_numpy(ort_outs[0]),\n",
    "    'attention_mask': torch.from_numpy(ort_inputs['attention_mask'])\n",
    "}\n",
    "pooling_layer.forward(features)\n",
    "print(features.keys())\n",
    "print(features['sentence_embedding'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9cee32",
   "metadata": {},
   "source": [
    "#### IV. Add Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183c1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_embeddings': tensor([[[ 0.6112, -0.4034,  0.4854,  ..., -0.1686,  0.5235, -0.0819],\n",
       "          [ 0.4675, -0.3926,  0.3994,  ..., -0.2330,  0.4120, -0.1260],\n",
       "          [ 0.5767, -0.4248,  0.4461,  ..., -0.1511,  0.4863, -0.0758],\n",
       "          ...,\n",
       "          [ 0.5466, -0.2550,  0.2605,  ..., -0.0381,  0.4918,  0.0092],\n",
       "          [ 0.5454, -0.2626,  0.3026,  ..., -0.0441,  0.4790,  0.0404],\n",
       "          [ 0.5621, -0.2934,  0.3254,  ..., -0.0600,  0.4934,  0.0442]],\n",
       " \n",
       "         [[ 0.5738, -0.3759,  0.5529,  ..., -0.1182,  0.5259, -0.0573],\n",
       "          [ 0.3484, -0.3386,  0.4806,  ..., -0.1488,  0.4365, -0.0916],\n",
       "          [ 0.5895, -0.3740,  0.5069,  ..., -0.1296,  0.5038, -0.0276],\n",
       "          ...,\n",
       "          [ 0.5081, -0.2275,  0.3310,  ..., -0.0255,  0.4946,  0.0071],\n",
       "          [ 0.4917, -0.2309,  0.3524,  ..., -0.0208,  0.4764,  0.0318],\n",
       "          [ 0.5092, -0.2576,  0.3779,  ..., -0.0224,  0.4903,  0.0379]],\n",
       " \n",
       "         [[ 0.4235, -0.4610,  0.2390,  ..., -0.2002,  0.2846, -0.2286],\n",
       "          [ 0.4001, -0.5642,  0.2557,  ..., -0.0176,  0.2391, -0.1557],\n",
       "          [ 0.3544, -0.5266,  0.2527,  ..., -0.0381,  0.2142, -0.1700],\n",
       "          ...,\n",
       "          [ 0.3768, -0.4015,  0.0735,  ..., -0.1616,  0.1231, -0.3453],\n",
       "          [-0.1518, -0.3033, -0.4957,  ...,  0.2593,  0.3008, -0.1726],\n",
       "          [ 0.0560, -0.1761,  0.0784,  ..., -0.0803,  0.1898, -0.0542]]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'sentence_embedding': tensor([[-0.0416, -0.2661, -0.2663,  ..., -0.0871,  0.1123, -0.1396],\n",
       "         [-0.0241, -0.2431, -0.2502,  ..., -0.0953,  0.0920, -0.1166],\n",
       "         [-0.0245, -0.1501, -0.1047,  ...,  0.0356,  0.0601, -0.1043]],\n",
       "        grad_fn=<MmBackward0>)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers.models import Dense\n",
    "dense_layer = Dense(768, 512, bias=False, activation_function=torch.nn.modules.linear.Identity())\n",
    "dense_layer.forward(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4113edd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['sentence_embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe945c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_onnx = [\n",
    "            features['sentence_embedding'][i].cpu().detach().numpy()\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646caa6",
   "metadata": {},
   "source": [
    "#### V. Verify Embedding with Embeddings Encoded with Hugging Face Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb5363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 7.389585\nMax relative difference: 1491.1345\n x: array([-3.352571e-01, -7.378923e-02, -2.863503e-01, -4.555894e-02,\n       -2.281259e-01,  1.402846e-01, -2.240530e-01, -1.598666e+00,\n        2.009055e-01,  1.197599e-01,  3.269672e-02,  2.298519e-01,...\n y: array([-4.161581e-02, -2.660530e-01, -2.662762e-01,  1.485295e-01,\n       -1.738283e-02,  1.110369e-01, -3.970781e-02,  1.896576e-01,\n        4.613394e-02, -5.534234e-03,  1.668322e-01,  2.779251e-02,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_sentences)):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_embedding_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_data_onnx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 7.389585\nMax relative difference: 1491.1345\n x: array([-3.352571e-01, -7.378923e-02, -2.863503e-01, -4.555894e-02,\n       -2.281259e-01,  1.402846e-01, -2.240530e-01, -1.598666e+00,\n        2.009055e-01,  1.197599e-01,  3.269672e-02,  2.298519e-01,...\n y: array([-4.161581e-02, -2.660530e-01, -2.662762e-01,  1.485295e-01,\n       -1.738283e-02,  1.110369e-01, -3.970781e-02,  1.896576e-01,\n        4.613394e-02, -5.534234e-03,  1.668322e-01,  2.779251e-02,..."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = SentenceTransformer(model_id) # From Huggingface\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")\n",
    "        \n",
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f6d26",
   "metadata": {},
   "source": [
    "# Resources:\n",
    "\n",
    "https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/models/Dense.py#L32\n",
    "https://github.com/huggingface/notebooks/blob/main/examples/onnx-export.ipynb\n",
    "https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v1\n",
    "\n",
    "# Other Models with Dense Layer that I Can Trace in TorchScript, but Not ONNX\n",
    "https://huggingface.co/sentence-transformers/clip-ViT-B-32-multilingual-v1\n",
    "\n",
    "(There are more models with dense layer but I haven't tried tracing in torch script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "847a0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = Dense.load(folder_path + '/2_Dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef9b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['token_embeddings', 'attention_mask', 'sentence_embedding'])\n",
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers.models import Pooling\n",
    "\n",
    "pooling_layer = Pooling(768, pooling_mode_mean_tokens=True)\n",
    "features = {\n",
    "    'token_embeddings':  torch.from_numpy(ort_outs[0]),\n",
    "    'attention_mask': torch.from_numpy(ort_inputs['attention_mask'])\n",
    "}\n",
    "pooling_layer.forward(features)\n",
    "print(features.keys())\n",
    "print(features['sentence_embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e78fe937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_embeddings': tensor([[[ 0.6112, -0.4034,  0.4854,  ..., -0.1686,  0.5235, -0.0819],\n",
       "          [ 0.4675, -0.3926,  0.3994,  ..., -0.2330,  0.4120, -0.1260],\n",
       "          [ 0.5767, -0.4248,  0.4461,  ..., -0.1511,  0.4863, -0.0758],\n",
       "          ...,\n",
       "          [ 0.5466, -0.2550,  0.2605,  ..., -0.0381,  0.4918,  0.0092],\n",
       "          [ 0.5454, -0.2626,  0.3026,  ..., -0.0441,  0.4790,  0.0404],\n",
       "          [ 0.5621, -0.2934,  0.3254,  ..., -0.0600,  0.4934,  0.0442]],\n",
       " \n",
       "         [[ 0.5738, -0.3759,  0.5529,  ..., -0.1182,  0.5259, -0.0573],\n",
       "          [ 0.3484, -0.3386,  0.4806,  ..., -0.1488,  0.4365, -0.0916],\n",
       "          [ 0.5895, -0.3740,  0.5069,  ..., -0.1296,  0.5038, -0.0276],\n",
       "          ...,\n",
       "          [ 0.5081, -0.2275,  0.3310,  ..., -0.0255,  0.4946,  0.0071],\n",
       "          [ 0.4917, -0.2309,  0.3524,  ..., -0.0208,  0.4764,  0.0318],\n",
       "          [ 0.5092, -0.2576,  0.3779,  ..., -0.0224,  0.4903,  0.0379]],\n",
       " \n",
       "         [[ 0.4235, -0.4610,  0.2390,  ..., -0.2002,  0.2846, -0.2286],\n",
       "          [ 0.4001, -0.5642,  0.2557,  ..., -0.0176,  0.2391, -0.1557],\n",
       "          [ 0.3544, -0.5266,  0.2527,  ..., -0.0381,  0.2142, -0.1700],\n",
       "          ...,\n",
       "          [ 0.3768, -0.4015,  0.0735,  ..., -0.1616,  0.1231, -0.3453],\n",
       "          [-0.1518, -0.3033, -0.4957,  ...,  0.2593,  0.3008, -0.1726],\n",
       "          [ 0.0560, -0.1761,  0.0784,  ..., -0.0803,  0.1898, -0.0542]]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'sentence_embedding': tensor([[-0.3353, -0.0738, -0.2864,  ..., -0.1908, -0.0159,  0.3217],\n",
       "         [-0.3503,  0.0078, -0.3547,  ..., -0.0885, -0.0692,  0.3034],\n",
       "         [-0.0854, -0.0509, -0.2186,  ...,  0.0735, -0.0921,  0.3836]],\n",
       "        grad_fn=<MmBackward0>)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model.forward(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bfe3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_onnx = [\n",
    "            features['sentence_embedding'][i].cpu().detach().numpy()\n",
    "            for i in range(len(input_sentences))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12435853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "None\n",
      "1\n",
      "None\n",
      "2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = SentenceTransformer(model_id) # From Huggingface\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")\n",
    "        \n",
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_data_onnx[i], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e093b2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense({'in_features': 768, 'out_features': 512, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbcf9bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense({'in_features': 768, 'out_features': 512, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83432f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model == dense_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af977e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model.state_dict == dense_layer.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "815c9ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model.activation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7a2b61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer.activation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17a2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
