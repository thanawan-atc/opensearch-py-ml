{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df3ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pprint\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import onnx\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import convert_graph_to_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef5caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = \"first sentence\"\n",
    "\n",
    "\n",
    "model_id = \"sentence-transformers/distiluse-base-multilingual-cased-v2\"\n",
    "model_raw = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfe22c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_2 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_3 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_4 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_5 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_6 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_7 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = transformers.FeatureExtractionPipeline(\n",
    "    model=transformers.AutoModel.from_pretrained(model_id),\n",
    "    tokenizer=transformers.AutoTokenizer.from_pretrained(model_id, use_fast=True),\n",
    "    framework=\"pt\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "config = model_pipeline.model.config\n",
    "tokenizer = model_pipeline.tokenizer\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_names, output_names, dynamic_axes, tokens = convert_graph_to_onnx.infer_shapes(\n",
    "        model_pipeline, \n",
    "        \"pt\"\n",
    "    )\n",
    "    ordered_input_names, model_args = convert_graph_to_onnx.ensure_valid_input(\n",
    "        model_pipeline.model, tokens, input_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceec51d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask']\n",
      "['output_0', 'output_1', 'output_2', 'output_3', 'output_4', 'output_5', 'output_6', 'output_7']\n",
      "{'input_ids': {0: 'batch', 1: 'sequence'}, 'attention_mask': {0: 'batch', 1: 'sequence'}, 'output_0': {0: 'batch', 1: 'sequence'}, 'output_1': {0: 'batch', 1: 'sequence'}, 'output_2': {0: 'batch', 1: 'sequence'}, 'output_3': {0: 'batch', 1: 'sequence'}, 'output_4': {0: 'batch', 1: 'sequence'}, 'output_5': {0: 'batch', 1: 'sequence'}, 'output_6': {0: 'batch', 1: 'sequence'}, 'output_7': {0: 'batch', 1: 'sequence'}}\n",
      "{'input_ids': tensor([[  101, 10747, 10124,   169, 45700, 37131,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "['input_ids', 'attention_mask']\n",
      "(tensor([[  101, 10747, 10124,   169, 45700, 37131,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1]]))\n"
     ]
    }
   ],
   "source": [
    "print(input_names)\n",
    "print(output_names)\n",
    "print(dynamic_axes)\n",
    "print(tokens)\n",
    "print(ordered_input_names)\n",
    "print(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2998963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence_embedding']\n",
      "{'input_ids': {0: 'batch', 1: 'sequence'}, 'attention_mask': {0: 'batch', 1: 'sequence'}, 'sentence_embedding': {0: 'batch'}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    del dynamic_axes[f\"output_{i}\"] # Delete unused output\n",
    "\n",
    "output_names = [\"sentence_embedding\"]\n",
    "dynamic_axes[\"sentence_embedding\"] = {0: 'batch'}\n",
    "\n",
    "# Check that everything worked\n",
    "print(output_names)\n",
    "print(dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae25d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers.models import Dense\n",
    "\n",
    "class SentenceTransformer(transformers.DistilBertModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Naming alias for ONNX output specification\n",
    "        # Makes it easier to identify the layer\n",
    "        self.sentence_embedding = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get the token embeddings from the base model\n",
    "        token_embeddings = super().forward(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "        )[0]\n",
    "        # Stack the pooling layer on top of it\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        # Add dense layer\n",
    "        intermediate_embeddings = self.sentence_embedding(sum_embeddings / sum_mask)\n",
    "        \n",
    "        feature_out = {'sentence_embedding': torch.FloatTensor(intermediate_embeddings)}\n",
    "        dense_layer = Dense(768, 512, bias=True, activation_function=torch.nn.modules.activation.Tanh())\n",
    "        dense_layer.forward(feature_out)\n",
    "        return feature_out['sentence_embedding']\n",
    "\n",
    "# Create the new model based on the config of the original pipeline\n",
    "model = SentenceTransformer(config=config).from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c45e593e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=1e-06\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 0.19937615\nMax relative difference: 353.38086\n x: array([ 2.924567e-02,  6.141232e-02, -4.720753e-02,  7.542608e-02,\n       -1.127941e-02, -2.926223e-02, -9.203118e-04,  7.731913e-03,\n        9.389930e-03, -5.170759e-02,  1.561492e-02, -1.805862e-02,...\n y: array([ 3.328726e-02, -1.804699e-02,  1.051623e-02, -6.104988e-02,\n        1.422415e-03, -3.669605e-03, -1.427884e-02,  4.272969e-03,\n       -4.546718e-02, -4.240783e-02,  1.901109e-02, -1.150605e-01,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=1e-06\n\nMismatched elements: 512 / 512 (100%)\nMax absolute difference: 0.19937615\nMax relative difference: 353.38086\n x: array([ 2.924567e-02,  6.141232e-02, -4.720753e-02,  7.542608e-02,\n       -1.127941e-02, -2.926223e-02, -9.203118e-04,  7.731913e-03,\n        9.389930e-03, -5.170759e-02,  1.561492e-02, -1.805862e-02,...\n y: array([ 3.328726e-02, -1.804699e-02,  1.051623e-02, -6.104988e-02,\n        1.422415e-03, -3.669605e-03, -1.427884e-02,  4.272969e-03,\n       -4.546718e-02, -4.240783e-02,  1.901109e-02, -1.150605e-01,..."
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(\n",
    "    model_raw.encode(span),\n",
    "    model(**tokenizer(span, return_tensors=\"pt\")).squeeze().detach().numpy(),\n",
    "    atol=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a7bf5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
