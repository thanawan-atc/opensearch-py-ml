{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba4c02d",
   "metadata": {},
   "source": [
    "# Demo Notebook to trace Sentence Transformers model\n",
    "\n",
    "#### [Download notebook](https://github.com/opensearch-project/opensearch-py-ml/blob/main/docs/source/examples/demo_tracing_model_torchscript_onnx.ipynb)\n",
    "\n",
    "This notebook provides a walkthrough guidance for users to trace models from Sentence Transformers in torchScript and onnx format. After tracing the model, customers can register the model to opensearch and generate embeddings.\n",
    "\n",
    "Remember, tracing model in torchScript or Onnx format at just two different options. We don't need to trace model in both ways. Here in our notebook we just want to show both ways. \n",
    "\n",
    "Step 0: Import packages and set up client\n",
    "\n",
    "Step 1: Save model in torchScript format\n",
    "\n",
    "Step 2: Register the saved torchScript model in Opensearch\n",
    "\n",
    "[The following steps are optional, just showing registering model in both ways and comparing the both embedding output]\n",
    "\n",
    "Step 3: Save model in Onnx format \n",
    "\n",
    "Step 4: Register the saved Onnx model in Opensearch\n",
    "\n",
    "Step 5: Generate Sentence Embedding with registered models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7011727e",
   "metadata": {},
   "source": [
    "## Step 0: Import packages and set up client\n",
    "Install required packages for opensearch_py_ml.sentence_transformer_model\n",
    "Install `opensearchpy` and `opensearch-py-ml` through pypi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a3e085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install opensearch-py opensearch-py-ml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c711bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"TracerWarning: torch.tensor\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"using SSL with verify_certs=False is insecure.\")\n",
    "\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel\n",
    "# import mlcommon to later register the model to OpenSearch Cluster\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c85ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_URL = 'https://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77442abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_client(cluster_url = CLUSTER_URL,\n",
    "                  username='admin',\n",
    "                  password='admin'):\n",
    "    '''\n",
    "    Get OpenSearch client\n",
    "    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443\n",
    "    :return: OpenSearch client\n",
    "    '''\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url],\n",
    "        http_auth=(username, password),\n",
    "        verify_certs=False\n",
    "    )\n",
    "    return client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e1cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python@3.8/lib/python3.8/site-packages/opensearchpy/connection/http_urllib3.py:199: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = get_os_client()\n",
    "\n",
    "# Connect to ml_common client with OpenSearch client\n",
    "ml_client = MLCommonClient(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9e0de",
   "metadata": {},
   "source": [
    "## Step 1: Save model in torchScript format\n",
    "\n",
    "`Opensearch-py-ml` plugin provides method `save_as_pt` which will trace a model in torchScript format and save the model in a zip file in your filesystem. \n",
    "\n",
    "Detailed documentation: https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.save_as_pt.html#opensearch_py_ml.ml_models.SentenceTransformerModel.save_as_pt\n",
    "\n",
    "\n",
    "Users need to provide a model id from sentence transformers (an example: `sentence-transformers/msmarco-distilbert-base-tas-b`). This model id is a huggingface model id. Example: https://huggingface.co/sentence-transformers/msmarco-distilbert-base-tas-b\n",
    "\n",
    "`save_as_pt` will download the model in filesystem and then trace the model with the given input strings.\n",
    "\n",
    "To get more direction about dummy input string please check this url: https://huggingface.co/docs/transformers/torchscript#dummy-inputs-and-standard-lengths\n",
    "\n",
    "after tracing the model (a .pt file will be generated), `save_as_pt` method zips `tokenizers.json` and torchScript (`.pt`) file and saves in the file system. \n",
    "\n",
    "User can register that model to opensearch to generate embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6405232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"hkunlp/instructor-large\"\n",
    "folder_path = \"sentence-transformer-torchscript/instructor-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39a1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(model_id, cache_folder=\"cache_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b0ff7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file is saved to  sentence-transformer-torchscript/instructor-large/instructor-large.pt\n",
      "zip file is saved to  sentence-transformer-torchscript/instructor-large/instructor-large.zip \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = SentenceTransformerModel(model=model,model_id=model_id, folder_path=folder_path, overwrite=True)\n",
    "model_path = pre_trained_model.save_as_pt(model_id=model_id, sentences=[\"for example providing a small sentence\", \"we can add multiple sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b7cbd",
   "metadata": {},
   "source": [
    "## Step 2: Register the saved torchScript model in Opensearch\n",
    "\n",
    "In the last step we saved a sentence transformer model in torchScript format. Now we will register that model in opensearch cluster. To do that we can take help of `register_model` method in `opensearch-py-ml` plugin.\n",
    "\n",
    "To register model, we need the zip file we just saved in the last step and a model config file. You can use `make_model_config_json` method to automatically generate the model config file and save it at `ml-commons_model_config.json` in model folder, or you can create a json file by yourself.\n",
    "\n",
    "Example of Model config file content can be:\n",
    "\n",
    "{\n",
    "  \"name\": \"sentence-transformers/msmarco-distilbert-base-tas-b\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"description\": \"This is a port of the DistilBert TAS-B Model to sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and is optimized for the task of semantic search.\",\n",
    "  \"model_format\": \"TORCH_SCRIPT\",\n",
    "  \"model_config\": {\n",
    "    \"model_type\": \"distilbert\",\n",
    "    \"embedding_dimension\": 768,\n",
    "    \"framework_type\": \"sentence_transformers\"\n",
    "  }\n",
    "}\n",
    "\n",
    "In either approach, you have to set `model_format` to be `TORCH_SCRIPT` so that internal system will look for the corresponding `.pt` file from the zip folder. \n",
    "\n",
    "Please refer to this doc: https://github.com/opensearch-project/ml-commons/blob/2.x/docs/model_serving_framework/text_embedding_model_examples.md\n",
    "\n",
    "\n",
    "Documentation for the method: https://opensearch-project.github.io/opensearch-py-ml/reference/api/ml_commons_register_api.html#opensearch_py_ml.ml_commons.MLCommonClient.register_model\n",
    "\n",
    "Related demo notebook about ml-commons plugin integration: https://opensearch-project.github.io/opensearch-py-ml/examples/demo_ml_commons_integration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d25f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-commons_model_config.json file is saved at :  sentence-transformer-torchscript/instructor-large/ml-commons_model_config.json\n"
     ]
    }
   ],
   "source": [
    "model_config_path_torch = pre_trained_model.make_model_config_json(model_format='TORCH_SCRIPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e9310c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks 135\n",
      "Sha1 value of the model file:  dc19d2d12f9dd92a2b5c10046dd80748ebf0ece25b0c65f6cdc7a1307cb044a9\n",
      "Model meta data was created successfully. Model Id:  Np-BbIoBx1PaKKd2oUEI\n",
      "uploading chunk 1 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 2 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 3 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 4 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 5 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 6 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 7 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 8 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 9 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 10 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 11 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 12 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 13 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 14 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 15 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 16 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 17 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 18 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 19 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 20 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 21 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 22 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 23 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 24 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 25 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 26 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 27 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 28 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 29 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 30 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 31 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 32 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 33 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 34 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 35 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 36 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 37 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 38 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 39 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 40 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 41 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 42 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 43 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 44 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 45 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 46 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 47 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 48 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 49 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 50 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 51 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 52 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 53 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 54 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 55 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 56 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 57 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 58 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 59 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 60 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 61 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 62 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 63 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 64 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 65 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 66 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 67 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 68 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 69 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 70 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 71 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 72 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 73 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 74 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 75 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 76 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 77 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 78 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 79 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 80 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 81 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 82 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 83 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 84 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 85 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 86 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 87 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 88 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 89 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 90 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 91 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 92 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 93 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 94 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 95 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 96 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 97 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 98 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 99 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 100 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 101 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 102 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 103 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 104 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 105 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 106 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 107 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 108 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 109 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 110 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 111 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 112 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 113 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 114 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 115 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 116 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 117 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 118 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 119 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 120 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 121 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 122 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 123 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 124 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 125 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 126 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 127 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 128 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 129 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 130 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 131 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 132 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 133 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 134 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 135 of 135\n",
      "Model id: {'status': 'Uploaded'}\n",
      "Model registered successfully\n",
      "Task ID: N5-CbIoBx1PaKKd2ZUEZ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Np-BbIoBx1PaKKd2oUEI'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.register_model(model_path, model_config_path_torch, isVerbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9dec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\"]\n",
    "\n",
    "# Generated embedding from torchScript\n",
    "\n",
    "embedding_output_torch = ml_client.generate_embedding(\"Np-BbIoBx1PaKKd2oUEI\", input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc8a5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02964081,\n",
       " -0.027421081,\n",
       " -0.009829031,\n",
       " 0.02755344,\n",
       " 0.035092562,\n",
       " 0.014475776,\n",
       " -0.0037900826,\n",
       " 0.008373647,\n",
       " -0.036055434,\n",
       " 0.05386531,\n",
       " 0.035365794,\n",
       " 0.01785825,\n",
       " 0.044933435,\n",
       " 0.033845108,\n",
       " -0.05881597,\n",
       " -0.00022746561,\n",
       " -0.03387527,\n",
       " 0.012096769,\n",
       " -0.027129449,\n",
       " -0.01782625,\n",
       " 0.04231302,\n",
       " -0.004925255,\n",
       " 0.019161735,\n",
       " 0.03359616,\n",
       " 0.015964525,\n",
       " 0.023440886,\n",
       " 0.0036820972,\n",
       " 0.02944205,\n",
       " 0.031555623,\n",
       " -0.051696245,\n",
       " 0.035307188,\n",
       " -0.029889585,\n",
       " -0.016751435,\n",
       " -0.02625368,\n",
       " -0.019084228,\n",
       " 0.02834905,\n",
       " 0.0062215896,\n",
       " 0.035276588,\n",
       " 0.0023043177,\n",
       " 0.022539517,\n",
       " -0.002801274,\n",
       " 0.031606887,\n",
       " -0.023278141,\n",
       " -0.01573268,\n",
       " 0.024965396,\n",
       " 0.009510316,\n",
       " -0.040802978,\n",
       " -0.057010293,\n",
       " 0.026688498,\n",
       " -0.02987496,\n",
       " -0.034362648,\n",
       " -0.07192495,\n",
       " -0.013895432,\n",
       " 0.0010260375,\n",
       " 0.027862363,\n",
       " -0.037236188,\n",
       " -0.0763143,\n",
       " 0.0414446,\n",
       " 0.072135374,\n",
       " -0.06949552,\n",
       " -0.035941187,\n",
       " 0.0077427183,\n",
       " -0.073430434,\n",
       " 0.031487167,\n",
       " 0.024000334,\n",
       " -0.05676593,\n",
       " 0.040309213,\n",
       " -0.047058217,\n",
       " 0.003814191,\n",
       " -0.01700211,\n",
       " 0.03969345,\n",
       " -0.04348376,\n",
       " 0.034130227,\n",
       " -0.08465621,\n",
       " -0.041372843,\n",
       " -0.023034582,\n",
       " 0.0360338,\n",
       " 0.03227035,\n",
       " -0.044940908,\n",
       " 0.03396894,\n",
       " 0.011700029,\n",
       " 0.01187888,\n",
       " 0.036496352,\n",
       " -0.0032547528,\n",
       " -0.03702323,\n",
       " 0.036515564,\n",
       " -0.044411004,\n",
       " 0.019182142,\n",
       " -0.0050560944,\n",
       " 0.043109093,\n",
       " -0.040557962,\n",
       " -0.030527618,\n",
       " -0.0063408785,\n",
       " -0.023601653,\n",
       " -0.025015013,\n",
       " 0.05230985,\n",
       " 0.051554617,\n",
       " -0.028387684,\n",
       " 0.024205828,\n",
       " 0.05480342,\n",
       " 0.029803632,\n",
       " 0.044243112,\n",
       " -0.043965634,\n",
       " 0.05649407,\n",
       " 0.007127709,\n",
       " -0.0080762915,\n",
       " -0.019265808,\n",
       " -0.022899572,\n",
       " -0.058926776,\n",
       " 0.010885086,\n",
       " 0.017274806,\n",
       " -0.060607247,\n",
       " -0.03952607,\n",
       " 0.038835026,\n",
       " 0.017184895,\n",
       " -0.002800541,\n",
       " 0.06732188,\n",
       " -0.03949937,\n",
       " -0.039951924,\n",
       " -0.052748166,\n",
       " 0.07192104,\n",
       " 0.021298172,\n",
       " -0.0041055004,\n",
       " 0.0025427614,\n",
       " -0.048127208,\n",
       " 0.021533811,\n",
       " -0.031067606,\n",
       " -0.04544885,\n",
       " -0.028414281,\n",
       " -0.0070064496,\n",
       " -0.016207578,\n",
       " 0.023990404,\n",
       " 0.026463391,\n",
       " -0.07050241,\n",
       " 0.0111866975,\n",
       " 0.015139633,\n",
       " -0.060488954,\n",
       " -0.008338247,\n",
       " 0.039704848,\n",
       " 0.07802472,\n",
       " -0.08217335,\n",
       " -0.048870068,\n",
       " -0.031314332,\n",
       " 0.013003977,\n",
       " 0.0058578453,\n",
       " 0.010400135,\n",
       " 0.03511824,\n",
       " -0.052411396,\n",
       " -0.022566741,\n",
       " -0.009082899,\n",
       " 0.055925578,\n",
       " -0.042981762,\n",
       " -0.029806498,\n",
       " 0.055296957,\n",
       " 0.0023282068,\n",
       " 0.044303045,\n",
       " -0.03873704,\n",
       " 0.013143263,\n",
       " -0.0008705051,\n",
       " 0.015982596,\n",
       " -0.036037847,\n",
       " 0.07151736,\n",
       " -0.022450106,\n",
       " 0.00884949,\n",
       " -0.06438309,\n",
       " -0.022095166,\n",
       " 0.0055970484,\n",
       " 0.09357037,\n",
       " -0.028212668,\n",
       " -0.043639176,\n",
       " -0.06588585,\n",
       " 0.03413977,\n",
       " 0.05411999,\n",
       " 0.02655648,\n",
       " -0.008589131,\n",
       " 0.023118364,\n",
       " 0.0659271,\n",
       " 0.025250984,\n",
       " -0.028781965,\n",
       " 0.030402716,\n",
       " -0.0073502166,\n",
       " -0.045085497,\n",
       " -0.056370467,\n",
       " 0.03693223,\n",
       " 0.04153667,\n",
       " -0.021284945,\n",
       " 0.014972795,\n",
       " 0.017652223,\n",
       " -0.02205855,\n",
       " -0.016889203,\n",
       " -0.0106424205,\n",
       " 0.050200727,\n",
       " -0.034103446,\n",
       " -0.017773079,\n",
       " 0.051187802,\n",
       " -0.015840776,\n",
       " -0.044892102,\n",
       " 0.049300283,\n",
       " -0.02796159,\n",
       " -0.00426662,\n",
       " -0.023304991,\n",
       " -0.0075094174,\n",
       " 0.008632759,\n",
       " 0.014190154,\n",
       " 0.021612598,\n",
       " 0.026704682,\n",
       " -0.015179183,\n",
       " 0.10169026,\n",
       " -0.03096399,\n",
       " 0.00047011985,\n",
       " -0.03953598,\n",
       " -0.05523827,\n",
       " -0.033802375,\n",
       " 0.049639497,\n",
       " 0.031121327,\n",
       " 0.07074206,\n",
       " -0.0058837524,\n",
       " -0.060522914,\n",
       " 0.02150004,\n",
       " 0.03460035,\n",
       " 0.03507618,\n",
       " 0.05654049,\n",
       " -0.043800216,\n",
       " -0.036817573,\n",
       " 0.02311499,\n",
       " 0.039833106,\n",
       " 0.0038758984,\n",
       " -0.044728123,\n",
       " 0.022566024,\n",
       " 0.028230986,\n",
       " -0.010100948,\n",
       " 0.0052037593,\n",
       " 0.010964605,\n",
       " 0.007201611,\n",
       " -0.011871758,\n",
       " -0.06843803,\n",
       " 0.027476145,\n",
       " 0.034484223,\n",
       " 0.004714141,\n",
       " 0.034232512,\n",
       " -0.021203203,\n",
       " 0.019822516,\n",
       " 0.04457441,\n",
       " -0.00420283,\n",
       " 0.014297858,\n",
       " -0.062467907,\n",
       " -0.008483689,\n",
       " -0.005436604,\n",
       " 0.07561666,\n",
       " -0.038855538,\n",
       " 0.043616474,\n",
       " -0.00091090694,\n",
       " 0.0022102112,\n",
       " 0.027201962,\n",
       " 0.010195624,\n",
       " 0.030332027,\n",
       " 0.065242484,\n",
       " 0.0014722304,\n",
       " -0.0038013894,\n",
       " 0.018930327,\n",
       " 0.05210591,\n",
       " 0.06507874,\n",
       " 0.028164564,\n",
       " -0.0078028818,\n",
       " 0.10458478,\n",
       " 0.013152333,\n",
       " 0.049472913,\n",
       " 0.052672744,\n",
       " 0.029194077,\n",
       " 0.002642154,\n",
       " 0.053651437,\n",
       " 0.03495848,\n",
       " -0.010357885,\n",
       " -0.012946051,\n",
       " 0.034364536,\n",
       " -0.078224644,\n",
       " 0.036539514,\n",
       " -0.039704233,\n",
       " 0.031342387,\n",
       " -0.016278366,\n",
       " -0.020059332,\n",
       " 0.062145792,\n",
       " 0.010372949,\n",
       " -0.020539306,\n",
       " 0.02027728,\n",
       " -0.026284916,\n",
       " -0.025837556,\n",
       " 0.04579295,\n",
       " -0.012013913,\n",
       " 0.04106321,\n",
       " -0.016609747,\n",
       " -0.045479327,\n",
       " -0.006295049,\n",
       " -0.08770526,\n",
       " -0.03530662,\n",
       " 1.7028617e-05,\n",
       " -0.042187486,\n",
       " -0.0002416075,\n",
       " -0.07775929,\n",
       " -0.039850395,\n",
       " -0.047413573,\n",
       " -0.02448861,\n",
       " 0.03260862,\n",
       " 0.010806826,\n",
       " 0.056483522,\n",
       " 0.020081023,\n",
       " 0.041560337,\n",
       " -0.027284795,\n",
       " -0.013836825,\n",
       " -0.02654622,\n",
       " -0.017683757,\n",
       " -0.02662508,\n",
       " -0.048746716,\n",
       " -0.011753244,\n",
       " 0.026375221,\n",
       " -5.0502153e-05,\n",
       " 0.028580138,\n",
       " -0.008420588,\n",
       " -0.06748084,\n",
       " -0.01670429,\n",
       " 0.0654471,\n",
       " 0.014145911,\n",
       " -0.044993952,\n",
       " -0.0360186,\n",
       " 0.013791967,\n",
       " 0.010284579,\n",
       " 0.015048133,\n",
       " -0.049356896,\n",
       " -0.015287467,\n",
       " 0.062145077,\n",
       " 0.049849283,\n",
       " 0.026725681,\n",
       " -0.0010523064,\n",
       " 0.01560801,\n",
       " -0.03242552,\n",
       " -0.025600247,\n",
       " -0.033319823,\n",
       " -0.041855887,\n",
       " -0.037683263,\n",
       " -0.039561458,\n",
       " -0.020955998,\n",
       " -0.020252537,\n",
       " -0.045402013,\n",
       " -0.036392573,\n",
       " -0.018300543,\n",
       " -0.010336057,\n",
       " 0.044191584,\n",
       " 0.03377827,\n",
       " 0.024256974,\n",
       " 0.0028672416,\n",
       " -0.058071766,\n",
       " -0.019318154,\n",
       " 0.06210961,\n",
       " -0.026906192,\n",
       " 0.008191645,\n",
       " -0.0617285,\n",
       " -0.023341248,\n",
       " 0.03785224,\n",
       " 0.029885586,\n",
       " 0.006351717,\n",
       " -0.03247256,\n",
       " 0.060646094,\n",
       " 0.041612152,\n",
       " 0.0014747574,\n",
       " 0.021763893,\n",
       " -0.017885996,\n",
       " 7.978966e-05,\n",
       " 0.0044453456,\n",
       " 0.009612417,\n",
       " -0.023282822,\n",
       " -0.05228524,\n",
       " -0.0179762,\n",
       " 0.0005632856,\n",
       " 0.033904437,\n",
       " -0.03440373,\n",
       " -0.017282631,\n",
       " -0.023156902,\n",
       " 0.03726568,\n",
       " 0.03726256,\n",
       " -0.0035206822,\n",
       " -0.005803861,\n",
       " -0.0007161617,\n",
       " -0.05091336,\n",
       " -0.012479965,\n",
       " -0.03400351,\n",
       " -0.01860636,\n",
       " 0.0059231934,\n",
       " 0.04983087,\n",
       " 0.02787254,\n",
       " -0.02832602,\n",
       " 0.031919096,\n",
       " 0.007232673,\n",
       " 0.03104191,\n",
       " 0.036529645,\n",
       " -0.033931658,\n",
       " 0.036357004,\n",
       " -0.0046791765,\n",
       " 0.0490708,\n",
       " 0.002508697,\n",
       " -0.01646593,\n",
       " -0.07043604,\n",
       " -0.0708497,\n",
       " -0.025713716,\n",
       " 0.011559817,\n",
       " -0.0062793093,\n",
       " 0.0113277575,\n",
       " 0.0046091825,\n",
       " -0.037792,\n",
       " -0.016211826,\n",
       " 0.014591851,\n",
       " -0.01216338,\n",
       " 0.039410964,\n",
       " -0.045684934,\n",
       " 0.03836782,\n",
       " -0.022523494,\n",
       " 0.0367586,\n",
       " -0.035728946,\n",
       " -0.0024671585,\n",
       " -0.030500105,\n",
       " -0.034312297,\n",
       " -0.013442077,\n",
       " 0.06759382,\n",
       " 0.0010008574,\n",
       " 0.027970623,\n",
       " 0.05702609,\n",
       " 0.03334538,\n",
       " -0.021265952,\n",
       " 0.031596348,\n",
       " 0.049395468,\n",
       " 0.007619152,\n",
       " -0.04686047,\n",
       " -0.005236663,\n",
       " -0.001611651,\n",
       " -0.026766792,\n",
       " -0.01424932,\n",
       " -0.022670202,\n",
       " 0.026624586,\n",
       " 0.0396082,\n",
       " -0.025251985,\n",
       " -0.011854506,\n",
       " 0.011860503,\n",
       " 0.016071277,\n",
       " -0.017882807,\n",
       " -0.07925518,\n",
       " 0.008351187,\n",
       " 0.004679373,\n",
       " -0.018180411,\n",
       " 0.021819336,\n",
       " 0.02342317,\n",
       " 0.010414877,\n",
       " 0.046135873,\n",
       " 0.019137215,\n",
       " -0.038328677,\n",
       " -0.04829029,\n",
       " 0.04385062,\n",
       " 0.014041178,\n",
       " -0.043975353,\n",
       " -0.05524951,\n",
       " -0.03443053,\n",
       " 0.01765821,\n",
       " 0.019852776,\n",
       " -0.033573844,\n",
       " -0.09222606,\n",
       " 0.00052305654,\n",
       " 0.023218578,\n",
       " -0.020514479,\n",
       " 0.052894343,\n",
       " 0.01813829,\n",
       " 0.011077618,\n",
       " 0.043608848,\n",
       " 0.0029602027,\n",
       " 0.04321823,\n",
       " -0.012270303,\n",
       " -0.030466639,\n",
       " 0.0316586,\n",
       " 0.055114295,\n",
       " -0.0204203,\n",
       " -0.033761058,\n",
       " -0.05199952,\n",
       " 0.031816028,\n",
       " 0.012279903,\n",
       " 0.02909012,\n",
       " 0.04195283,\n",
       " -0.036660388,\n",
       " -0.038098022,\n",
       " -0.016438402,\n",
       " 0.031055681,\n",
       " -0.03124871,\n",
       " 0.011974357,\n",
       " 0.03689926,\n",
       " 0.036334988,\n",
       " -0.035502322,\n",
       " -0.04069703,\n",
       " -0.024433138,\n",
       " 0.026976258,\n",
       " 0.06716143,\n",
       " -0.020755522,\n",
       " -0.0085779885,\n",
       " -0.042084258,\n",
       " 0.009956027,\n",
       " 0.047366306,\n",
       " -0.023136124,\n",
       " -0.08752507,\n",
       " 0.011868308,\n",
       " -0.011032721,\n",
       " -0.021317955,\n",
       " 0.0351816,\n",
       " 0.04692627,\n",
       " 0.057259146,\n",
       " 0.06937585,\n",
       " -0.004051483,\n",
       " 0.045093477,\n",
       " -0.027056487,\n",
       " 0.033005223,\n",
       " -0.035627406,\n",
       " -0.029922167,\n",
       " 0.008420375,\n",
       " -0.043635905,\n",
       " -0.035730034,\n",
       " -0.048104506,\n",
       " -0.030994039,\n",
       " -0.054565873,\n",
       " -0.027831081,\n",
       " 0.0241073,\n",
       " -0.039722208,\n",
       " 0.034809794,\n",
       " 0.020555608,\n",
       " 0.01686954,\n",
       " 0.026990572,\n",
       " -0.02811225,\n",
       " -0.018148037,\n",
       " -0.0371803,\n",
       " -0.06963688,\n",
       " -0.0010756528,\n",
       " 0.057243552,\n",
       " 0.0074096196,\n",
       " -0.0051886486,\n",
       " 0.0028370884,\n",
       " 0.02404412,\n",
       " 0.025556127,\n",
       " 0.00065033743,\n",
       " -0.055665296,\n",
       " 0.031844728,\n",
       " 0.025432343,\n",
       " -0.03970463,\n",
       " -0.034744963,\n",
       " -0.017884403,\n",
       " 0.012771523,\n",
       " 0.0039368505,\n",
       " -0.04486551,\n",
       " 0.026030116,\n",
       " -0.00034363096,\n",
       " -0.015507696,\n",
       " -0.057885,\n",
       " 0.052487116,\n",
       " -0.0104089,\n",
       " -0.042511355,\n",
       " -0.024986533,\n",
       " 0.0117489295,\n",
       " 0.01775115,\n",
       " 0.05080724,\n",
       " -0.011865169,\n",
       " -0.017867355,\n",
       " 0.009739869,\n",
       " 0.03609452,\n",
       " 0.00846779,\n",
       " 0.012933816,\n",
       " -0.040541016,\n",
       " 0.060439512,\n",
       " -0.03176614,\n",
       " 0.011717948,\n",
       " -0.085282885,\n",
       " 0.023000378,\n",
       " -0.014957034,\n",
       " 0.009824775,\n",
       " -0.02193969,\n",
       " 0.036165282,\n",
       " -0.060959812,\n",
       " 0.040907707,\n",
       " -0.0325876,\n",
       " 0.005788114,\n",
       " -0.03062917,\n",
       " 0.009316725,\n",
       " -0.063144945,\n",
       " 0.02048054,\n",
       " -0.03574877,\n",
       " -0.022038193,\n",
       " -0.069644324,\n",
       " 0.017905189,\n",
       " -0.057346135,\n",
       " -0.009894227,\n",
       " -0.02192431,\n",
       " 0.016356517,\n",
       " -0.03320754,\n",
       " 0.007513054,\n",
       " -0.013883386,\n",
       " -0.058696505,\n",
       " 0.023013556,\n",
       " 0.019829264,\n",
       " 0.025835697,\n",
       " 0.028972503,\n",
       " -0.024961626,\n",
       " -0.011747188,\n",
       " 0.026357139,\n",
       " -0.047693886,\n",
       " -0.031066246,\n",
       " -0.01481749,\n",
       " 0.014398401,\n",
       " 0.010050747,\n",
       " 0.037690762,\n",
       " 0.053865694,\n",
       " -0.062975295,\n",
       " -0.04339388,\n",
       " 0.08298237,\n",
       " 0.040764585,\n",
       " 0.00993065,\n",
       " -0.007738701,\n",
       " 0.021033216,\n",
       " 0.074039795,\n",
       " 0.02542721,\n",
       " -0.033633865,\n",
       " -0.008177171,\n",
       " -0.0355028,\n",
       " -0.010606885,\n",
       " -0.002951416,\n",
       " -0.01733788,\n",
       " 0.027327657,\n",
       " 0.0143532045,\n",
       " -0.041312672,\n",
       " -0.03516879,\n",
       " 0.093545884,\n",
       " 0.03672157,\n",
       " 0.032742545,\n",
       " -0.0043453868,\n",
       " -0.08182324,\n",
       " 0.015170618,\n",
       " 0.015869377,\n",
       " -0.025663653,\n",
       " 0.027085569,\n",
       " 0.010653294,\n",
       " -0.034159902,\n",
       " 0.046198413,\n",
       " -0.0152302785,\n",
       " -0.0019167543,\n",
       " 0.03782958,\n",
       " 0.036530923,\n",
       " -0.013282531,\n",
       " 0.0068595554,\n",
       " -0.034954045,\n",
       " 0.015461633,\n",
       " 0.039171048,\n",
       " -0.073425576,\n",
       " -0.016443625,\n",
       " -0.04263049,\n",
       " 0.06535936,\n",
       " -0.05584126,\n",
       " 0.043758094,\n",
       " 0.04365406,\n",
       " -0.007157804,\n",
       " 0.033866428,\n",
       " -0.0051501584,\n",
       " -0.050864406,\n",
       " 0.016148206,\n",
       " -0.049670257,\n",
       " 0.07412171,\n",
       " -0.01379529,\n",
       " -0.042363167,\n",
       " 0.0643597,\n",
       " 0.011587772,\n",
       " -0.044764634,\n",
       " 0.034770034,\n",
       " -0.005962366,\n",
       " 0.008922669,\n",
       " 0.016308445,\n",
       " 0.03256018,\n",
       " -0.051188923,\n",
       " 0.0046171984,\n",
       " -0.030155247,\n",
       " 0.013711125,\n",
       " -0.061041877,\n",
       " -0.037885245,\n",
       " 0.02069318,\n",
       " -0.03847883,\n",
       " -0.0066301487,\n",
       " 0.036328,\n",
       " -0.0413433,\n",
       " 0.02182154,\n",
       " 0.021579275,\n",
       " -0.039396044,\n",
       " -0.044486865,\n",
       " 0.014731591,\n",
       " 0.020773564,\n",
       " 0.006702282,\n",
       " -0.009645651,\n",
       " -0.020191027,\n",
       " -0.011324271,\n",
       " 0.036804013,\n",
       " -0.0016640739,\n",
       " -0.016074529,\n",
       " 0.021387083,\n",
       " 0.015309088,\n",
       " -0.04072251,\n",
       " -0.033366513,\n",
       " 0.027056312,\n",
       " 0.010714233,\n",
       " -0.023702173,\n",
       " 0.029181119,\n",
       " -0.015997643,\n",
       " 0.005106616,\n",
       " 0.04296162,\n",
       " 0.011310856,\n",
       " 0.016878603,\n",
       " -0.06363327,\n",
       " -0.011448954,\n",
       " 0.013797948,\n",
       " 0.03162622,\n",
       " 0.05883039,\n",
       " -0.017570447,\n",
       " 0.026983736,\n",
       " 0.029324478,\n",
       " 0.01629302,\n",
       " 0.026401179,\n",
       " -0.052098237,\n",
       " -0.025989363,\n",
       " 0.020081172,\n",
       " -0.04087743,\n",
       " 0.029463837,\n",
       " -0.057836495,\n",
       " -0.066234894,\n",
       " -0.030467188,\n",
       " -0.02642051,\n",
       " 0.0020977564,\n",
       " 0.0052585807,\n",
       " -0.048655584,\n",
       " -0.0010175323,\n",
       " 0.025985753,\n",
       " 0.025043393,\n",
       " -0.033904657,\n",
       " -0.07471273,\n",
       " -0.022892645,\n",
       " -0.046787865,\n",
       " 0.03466984,\n",
       " 0.03340655,\n",
       " -0.013116362,\n",
       " 0.0078684725,\n",
       " -0.048287243,\n",
       " -0.031410843,\n",
       " 0.04201486,\n",
       " -0.016662072,\n",
       " -0.030084899,\n",
       " 0.061669346,\n",
       " 0.059268665,\n",
       " -0.043116204,\n",
       " -0.003659082,\n",
       " 0.06438735,\n",
       " -0.047009837,\n",
       " 0.043347508,\n",
       " 0.003654527,\n",
       " 0.07491803,\n",
       " 0.03240364,\n",
       " 0.047917847,\n",
       " -0.03564298,\n",
       " -0.032188635,\n",
       " -0.04324781,\n",
       " -0.041936547,\n",
       " -0.046562392,\n",
       " 0.01683788,\n",
       " 0.054766636]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output_torch['inference_results'][1]['output'][0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e166318e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "None\n",
      "1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "original_pre_trained_model = model\n",
    "original_embedding_data = list(\n",
    "    original_pre_trained_model.encode(input_sentences, convert_to_numpy=True)\n",
    ")\n",
    "        \n",
    "for i in range(len(input_sentences)):\n",
    "    print(i)\n",
    "    print(np.testing.assert_allclose(original_embedding_data[i], embedding_output_torch['inference_results'][i]['output'][0]['data'], rtol=1e-03, atol=1e-05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee235b",
   "metadata": {},
   "source": [
    "## Step 3: Save model in Onnx format\n",
    "\n",
    "`Opensearch-py-ml` plugin provides method `save_as_onnx` which will trace a model in ONNX format and save the model in a zip file in your filesystem. \n",
    "\n",
    "Detailed documentation: https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.save_as_onnx.html#opensearch_py_ml.ml_models.SentenceTransformerModel.save_as_onnx\n",
    "\n",
    "\n",
    "Users need to provide a model id from sentence transformers (an example: `sentence-transformers/msmarco-distilbert-base-tas-b`). `save_as_onnx` will download the model in filesystem and then trace the model.\n",
    "\n",
    "after tracing the model (a .onnx file will be generated), `save_as_onnx` method zips `tokenizers.json` and torchScript (`.onnx`) file and saves in the file system. \n",
    "\n",
    "User can register that model to opensearch to generate embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fff842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
    "folder_path = \"sentence-transformer-onnx/msmarco-distilbert-base-tas-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d6b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 15\n",
      "Loading pipeline (model: sentence-transformers/msmarco-distilbert-base-tas-b, tokenizer: sentence-transformers/msmarco-distilbert-base-tas-b)\n",
      "Creating folder sentence-transformer-onnx/msmarco-distilbert-base-tas-b/onnx\n",
      "Using framework PyTorch: 1.13.1+cu117\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n",
      "zip file is saved to  sentence-transformer-onnx/msmarco-distilbert-base-tas-b/msmarco-distilbert-base-tas-b.zip \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = SentenceTransformerModel(model_id=model_id, folder_path=folder_path, overwrite=True)\n",
    "model_path_onnx = pre_trained_model.save_as_onnx(model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed5665",
   "metadata": {},
   "source": [
    "## Step 4: Register the saved Onnx model in Opensearch\n",
    "\n",
    "In the last step we saved a sentence transformer model in ONNX format. Now we will register that model in opensearch cluster. To do that we can take help of `register_model` method in `opensearch-py-ml` plugin.\n",
    "\n",
    "To register model, we need the zip file we just saved in the last step and a model config file. You can use `make_model_config_json` method to automatically generate the model config file and save it at `ml-commons_model_config.json` in model folder, or you can create a json file by yourself.\n",
    "\n",
    "{\n",
    "  \"name\": \"sentence-transformers/msmarco-distilbert-base-tas-b\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"description\": \"This is a port of the DistilBert TAS-B Model to sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and is optimized for the task of semantic search.\",\n",
    "  \"model_format\": \"ONNX\",\n",
    "  \"model_config\": {\n",
    "    \"model_type\": \"distilbert\",\n",
    "    \"embedding_dimension\": 768,\n",
    "    \"framework_type\": \"sentence_transformers\",\n",
    "    \"pooling_mode\":\"cls\",\n",
    "    \"normalize_result\":\"false\"\n",
    "  }\n",
    "}\n",
    "\n",
    "In either approach, you have to set `model_format` to be `ONNX` so that internal system will look for the corresponding `.onnx` file from the zip folder.\n",
    "\n",
    "Please refer to this doc: https://github.com/opensearch-project/ml-commons/blob/2.x/docs/model_serving_framework/text_embedding_model_examples.md\n",
    "\n",
    "\n",
    "Documentation for the method: https://opensearch-project.github.io/opensearch-py-ml/reference/api/ml_commons_register_api.html#opensearch_py_ml.ml_commons.MLCommonClient.register_model\n",
    "\n",
    "Related demo notebook about ml-commons plugin integration: https://opensearch-project.github.io/opensearch-py-ml/examples/demo_ml_commons_integration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e475f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-commons_model_config.json file is saved at :  sentence-transformer-onnx/msmarco-distilbert-base-tas-b/ml-commons_model_config.json\n"
     ]
    }
   ],
   "source": [
    "model_config_path_onnx = pre_trained_model.make_model_config_json(model_format='ONNX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661c3f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks 27\n",
      "Sha1 value of the model file:  81c950d07eaa21705dd94cec0f127efec42844cd1995502452764777460517d4\n",
      "Model meta data was created successfully. Model Id:  49jz4okB2Ly7dmqcNrWD\n",
      "uploading chunk 1 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 2 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 3 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 4 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 5 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 6 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 7 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 8 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 9 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 10 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 11 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 12 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 13 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 14 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 15 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 16 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 17 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 18 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 19 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 20 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 21 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 22 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 23 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 24 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 25 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 26 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "uploading chunk 27 of 27\n",
      "Model id: {'status': 'Uploaded'}\n",
      "Model registered successfully\n",
      "Task ID: 5Njz4okB2Ly7dmqcW7XA\n",
      "Model deployed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'49jz4okB2Ly7dmqcNrWD'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.register_model(model_path_onnx, model_config_path_onnx, isVerbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22c708",
   "metadata": {},
   "source": [
    "## Step 5: Generate Sentence Embedding\n",
    "\n",
    "Now after loading these models in memory, we can generate embedding for sentences. We can provide a list of sentences to get a list of embedding for the sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc5a796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Now using this model we can generate sentence embedding.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_sentences = [\"first sentence\", \"second sentence\"]\n",
    "\n",
    "# Generated embedding from torchScript\n",
    "\n",
    "embedding_output_torch = ml_client.generate_embedding(\"4djw4okB2Ly7dmqcT7Xp\", input_sentences)\n",
    "\n",
    "#just taking embedding for the first sentence\n",
    "data_torch = embedding_output_torch[\"inference_results\"][0][\"output\"][0][\"data\"]\n",
    "\n",
    "# Generated embedding from onnx\n",
    "\n",
    "embedding_output_onnx = ml_client.generate_embedding(\"49jz4okB2Ly7dmqcNrWD\", input_sentences)\n",
    "\n",
    "# Just taking embedding for the first sentence\n",
    "data_onnx = embedding_output_onnx[\"inference_results\"][0][\"output\"][0][\"data\"]\n",
    "\n",
    "# Now we can check if there's any significant difference between two outputs\n",
    "\n",
    "print(np.testing.assert_allclose(data_torch, data_onnx, rtol=1e-03, atol=1e-05))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
