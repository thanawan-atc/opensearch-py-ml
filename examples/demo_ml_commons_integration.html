<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Demo Notebook for MLCommons Integration &mdash; Opensearch-py-ml 1.0.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pre-trained models" href="../reference/pre_trained_models.html" />
    <link rel="prev" title="Demo Notebook to trace Sentence Transformers model" href="demo_tracing_model_torchscript_onnx.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Opensearch-py-ml
          </a>
              <div class="version">
                1.0.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">API Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#demo-notebooks-for-data-exploration-panda-like-dataframe">Demo notebooks for Data Exploration Panda like DataFrame</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#demo-notebooks-for-model-training-and-tracing">Demo notebooks for Model Training and Tracing</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#demo-notebooks-for-ml-commons-plugin-integration">Demo notebooks for ML Commons plugin integration</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Demo Notebook for MLCommons Integration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Download-notebook">Download notebook</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reference/pre_trained_models.html">Pre-trained models</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Opensearch-py-ml</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Examples</a></li>
      <li class="breadcrumb-item active">Demo Notebook for MLCommons Integration</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/demo_ml_commons_integration.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Demo-Notebook-for-MLCommons-Integration">
<h1>Demo Notebook for MLCommons Integration<a class="headerlink" href="#Demo-Notebook-for-MLCommons-Integration" title="Permalink to this heading"></a></h1>
<section id="Download-notebook">
<h2><a class="reference external" href="https://github.com/opensearch-project/opensearch-py-ml/blob/main/docs/source/examples/demo_ml_commons_integration.ipynb">Download notebook</a><a class="headerlink" href="#Download-notebook" title="Permalink to this heading"></a></h2>
<p>This notebook provides a walkthrough guidance for users to invoke MLCommons apis to upload ml models to opensearch cluster</p>
<p>Step 0: Import packages and set up client</p>
<p>Step 1: Upload NLP model from local file to Opensearch cluster</p>
<p>Step 2: Load Model</p>
<p>Step 3: Get Task</p>
<p>Step 4: Get Model</p>
<p>Step 5: Generate Sentence Embedding</p>
<p>Step 6: Unload Model</p>
<p>Step 7: Delete Model</p>
<section id="Step-0:-Import-packages-and-set-up-client">
<h3>Step 0: Import packages and set up client<a class="headerlink" href="#Step-0:-Import-packages-and-set-up-client" title="Permalink to this heading"></a></h3>
<p>Install required packages for opensearch_py_ml.sentence_transformer_model Install <code class="docutils literal notranslate"><span class="pre">opensearchpy</span></code> and <code class="docutils literal notranslate"><span class="pre">opensearch-py-ml</span></code> through pypi</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>opensearch-py<span class="w"> </span>opensearch-py-ml
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>deprecated
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-yellow-fg">DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621</span><span class="ansi-yellow-fg">
</span>Collecting deprecated
  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)
Requirement already satisfied: wrapt&lt;2,&gt;=1.10 in /usr/local/lib/python3.9/site-packages (from deprecated) (1.13.3)
Installing collected packages: deprecated
<span class="ansi-yellow-fg">  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621</span><span class="ansi-yellow-fg">
</span><span class="ansi-yellow-fg">DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621</span><span class="ansi-yellow-fg">
</span>Successfully installed deprecated-1.2.14

<span class="ansi-bold">[</span><span class="ansi-blue-fg">notice</span><span class="ansi-bold">]</span> A new release of pip is available: <span class="ansi-red-fg">23.1</span> -&gt; <span class="ansi-green-fg">23.1.2</span>
<span class="ansi-bold">[</span><span class="ansi-blue-fg">notice</span><span class="ansi-bold">]</span> To update, run: <span class="ansi-green-fg">python3.9 -m pip install --upgrade pip</span>
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;Unverified HTTPS request&quot;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">opensearchpy</span> <span class="kn">import</span> <span class="n">OpenSearch</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CLUSTER_URL</span> <span class="o">=</span> <span class="s1">&#39;https://localhost:9200&#39;</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_os_client</span><span class="p">(</span><span class="n">cluster_url</span> <span class="o">=</span> <span class="n">CLUSTER_URL</span><span class="p">,</span>
                  <span class="n">username</span><span class="o">=</span><span class="s1">&#39;admin&#39;</span><span class="p">,</span>
                  <span class="n">password</span><span class="o">=</span><span class="s1">&#39;admin&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Get OpenSearch client</span>
<span class="sd">    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443</span>
<span class="sd">    :return: OpenSearch client</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">OpenSearch</span><span class="p">(</span>
        <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="n">cluster_url</span><span class="p">],</span>
        <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">),</span>
        <span class="n">verify_certs</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">client</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">client</span> <span class="o">=</span> <span class="n">get_os_client</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.9/site-packages/opensearchpy/connection/http_urllib3.py:199: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.
  warnings.warn(
</pre></div></div>
</div>
</section>
<section id="Step-1:-Upload-NLP-model-from-local-file-to-Opensearch-cluster">
<h3>Step 1: Upload NLP model from local file to Opensearch cluster<a class="headerlink" href="#Step-1:-Upload-NLP-model-from-local-file-to-Opensearch-cluster" title="Permalink to this heading"></a></h3>
<p>We can upload machine learning models to Opensearch cluster using MLCommons register_model api. In this demo we will show how can we upload model</p>
<p>From Opensearch 2.8, to register a model we need to have a model group. First we need to register a model group and use the model group id to register a model. For registering a model group we can look at this doc:</p>
<p><a class="reference external" href="https://github.com/opensearch-project/ml-commons/blob/2.x/docs/model_access_control.md#registering-a-model-group">https://github.com/opensearch-project/ml-commons/blob/2.x/docs/model_access_control.md#registering-a-model-group</a></p>
<p>In our following example, we created a group and using the group id to register a model.</p>
<p>From Opensearch 2.6, we introduced pre-trained models: <a class="reference external" href="https://opensearch.org/docs/latest/ml-commons-plugin/pretrained-models/">https://opensearch.org/docs/latest/ml-commons-plugin/pretrained-models/</a></p>
<ul class="simple">
<li><p>One thing to remember, if we don’t have any ml node then registering model might throw exception. In that case we need to update this setting: <a class="reference external" href="https://github.com/opensearch-project/ml-commons/blob/main/build.gradle#L46">https://github.com/opensearch-project/ml-commons/blob/main/build.gradle#L46</a></p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">opensearch_py_ml.ml_commons</span> <span class="kn">import</span> <span class="n">MLCommonClient</span>
<span class="n">ml_client</span> <span class="o">=</span> <span class="n">MLCommonClient</span><span class="p">(</span><span class="n">client</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">model_id</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">register_pretrained_model</span><span class="p">(</span><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;huggingface/sentence-transformers/all-MiniLM-L12-v2&quot;</span><span class="p">,</span> <span class="n">model_version</span> <span class="o">=</span> <span class="s2">&quot;1.0.1&quot;</span><span class="p">,</span> <span class="n">model_format</span> <span class="o">=</span> <span class="s2">&quot;TORCH_SCRIPT&quot;</span><span class="p">,</span> <span class="n">model_group_id</span> <span class="o">=</span> <span class="s2">&quot;d4hfsYgBFp6IJxCcqpwi&quot;</span><span class="p">,</span> <span class="n">deploy_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">wait_until_deployed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model was registered successfully. Model Id:  7aF5sYgBZqn0fcHifav4
</pre></div></div>
</div>
<p>We can also upload model from our own file system or URL. But to do that we need to update couple cluster settings:</p>
<p>To register from url: plugins.ml_commons.allow_registering_model_via_url To register from file system: plugins.ml_commons.allow_registering_model_via_local_file</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>By default, both of these values are `False`, we need to update to `True`
</pre></div>
</div>
<p>To demonstrate, we download the model zip file from the url: <a class="reference external" href="https://github.com/opensearch-project/ml-commons/raw/2.x/ml-algorithms/src/test/resources/org/opensearch/ml/engine/algorithms/text_embedding/all-MiniLM-L6-v2_torchscript_sentence-transformer.zip?raw=true">https://github.com/opensearch-project/ml-commons/raw/2.x/ml-algorithms/src/test/resources/org/opensearch/ml/engine/algorithms/text_embedding/all-MiniLM-L6-v2_torchscript_sentence-transformer.zip?raw=true</a></p>
<p>To upload model to the cluster, we need a zip file containing a torchScript file (.pt extension) and a tokenizer.json file. Please refer to the previous download. We also need a json file with defining the config information with following these request fields:</p>
<p><a class="reference external" href="https://opensearch.org/docs/latest/ml-commons-plugin/api/#request-fields">https://opensearch.org/docs/latest/ml-commons-plugin/api/#request-fields</a></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">model_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/sentence-transformers_all-MiniLM-L6-v2-1.0.0-torch_script.zip&#39;</span>
<span class="n">model_config_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/all-MiniLM-L6-v2_torchscript.json&#39;</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">all-MiniLM-L6-v2_torchscript.json content:</span>

<span class="sd">{</span>
<span class="sd">    &quot;name&quot;: &quot;all-MiniLM-L6-v2&quot;,</span>
<span class="sd">    &quot;version&quot;: 1,</span>
<span class="sd">    &quot;model_format&quot;: &quot;TORCH_SCRIPT&quot;,</span>
<span class="sd">    &quot;model_config&quot;: {</span>
<span class="sd">        &quot;model_type&quot;: &quot;bert&quot;,</span>
<span class="sd">        &quot;embedding_dimension&quot;: 384,</span>
<span class="sd">        &quot;framework_type&quot;: &quot;sentence_transformers&quot;</span>
<span class="sd">    }</span>
<span class="sd">}</span>
<span class="sd">&quot;&quot;&quot;</span>


<span class="n">model_id_file_system</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">register_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">model_config_path</span><span class="p">,</span> <span class="n">model_group_id</span> <span class="o">=</span> <span class="s2">&quot;d4hfsYgBFp6IJxCcqpwi&quot;</span><span class="p">,</span> <span class="n">isVerbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total number of chunks 10
Sha1 value of the model file:  3ead6e8725322ff54ef9137c453132046098d7e6494945283b8fc980c9123675
Model meta data was created successfully. Model Id:  4oh9sYgBFp6IJxCclpx2
uploading chunk 1 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 2 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 3 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 4 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 5 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 6 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 7 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 8 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 9 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 10 of 10
Model id: {&#39;status&#39;: &#39;Uploaded&#39;}
Model registered successfully
Model deployed successfully
</pre></div></div>
</div>
</section>
<section id="Step-2:-Load-Model">
<h3>Step 2: Load Model<a class="headerlink" href="#Step-2:-Load-Model" title="Permalink to this heading"></a></h3>
<p>In the last step we upload a model and the model id is: <code class="docutils literal notranslate"><span class="pre">7KFfsYgBZqn0fcHi8Ku0</span></code>. Now we will load this model in opensearch memory.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">load_model_output</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">deploy_model</span><span class="p">(</span><span class="s2">&quot;7KFfsYgBZqn0fcHi8Ku0&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">load_model_output</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model deployed successfully
{&#39;model_id&#39;: &#39;7KFfsYgBZqn0fcHi8Ku0&#39;, &#39;task_type&#39;: &#39;DEPLOY_MODEL&#39;, &#39;function_name&#39;: &#39;TEXT_EMBEDDING&#39;, &#39;state&#39;: &#39;FAILED&#39;, &#39;worker_node&#39;: [&#39;QkNLom65QCiU1AwA4fRQHA&#39;, &#39;BJ0OvIWHTJuEJu2muBVRIA&#39;], &#39;create_time&#39;: 1686603192569, &#39;last_update_time&#39;: 1686603193467, &#39;error&#39;: &#39;{&#34;QkNLom65QCiU1AwA4fRQHA&#34;:&#34;Duplicate deploy model task&#34;,&#34;BJ0OvIWHTJuEJu2muBVRIA&#34;:&#34;Duplicate deploy model task&#34;}&#39;, &#39;is_async&#39;: True}
</pre></div></div>
</div>
</section>
<section id="Step-3:-Get-Task">
<h3>Step 3: Get Task<a class="headerlink" href="#Step-3:-Get-Task" title="Permalink to this heading"></a></h3>
<p>When we invoke load model api of mlcommons plugin, a task get created. We can see the task id (<code class="docutils literal notranslate"><span class="pre">j9uRoIUBqB81FWKi_Xqu</span></code>) from previous output. Now, we can get the detailed information of the task using this task id</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">task_info</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">get_task_info</span><span class="p">(</span><span class="s2">&quot;kNuaoIUBqB81FWKimHoo&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">task_info</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;model_id&#39;: &#39;jtuRoIUBqB81FWKil3qA&#39;, &#39;task_type&#39;: &#39;LOAD_MODEL&#39;, &#39;function_name&#39;: &#39;TEXT_EMBEDDING&#39;, &#39;state&#39;: &#39;COMPLETED&#39;, &#39;worker_node&#39;: &#39;56rNfEbPSG6p8ZZli59Zpg,Lncik04uQxe-cw3BC14wNA&#39;, &#39;create_time&#39;: 1673436764200, &#39;last_update_time&#39;: 1673436768619, &#39;is_async&#39;: True}
</pre></div></div>
</div>
</section>
<section id="Step-4:-Get-Model">
<h3>Step 4: Get Model<a class="headerlink" href="#Step-4:-Get-Model" title="Permalink to this heading"></a></h3>
<p>With using the model id, we can also pull information about the model metadata from the opensearch cluster.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">model_info</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">get_model_info</span><span class="p">(</span><span class="s2">&quot;7KFfsYgBZqn0fcHi8Ku0&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model_info</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;name&#39;: &#39;huggingface/sentence-transformers/all-MiniLM-L12-v2&#39;, &#39;model_group_id&#39;: &#39;d4hfsYgBFp6IJxCcqpwi&#39;, &#39;algorithm&#39;: &#39;TEXT_EMBEDDING&#39;, &#39;model_version&#39;: &#39;1&#39;, &#39;model_format&#39;: &#39;TORCH_SCRIPT&#39;, &#39;model_state&#39;: &#39;DEPLOYED&#39;, &#39;model_content_size_in_bytes&#39;: 134568911, &#39;model_content_hash_value&#39;: &#39;f8012a4e6b5da1f556221a12160d080157039f077ab85a5f6b467a47247aad49&#39;, &#39;model_config&#39;: {&#39;model_type&#39;: &#39;bert&#39;, &#39;embedding_dimension&#39;: 384, &#39;framework_type&#39;: &#39;SENTENCE_TRANSFORMERS&#39;, &#39;all_config&#39;: &#39;{&#34;_name_or_path&#34;:&#34;microsoft/MiniLM-L12-H384-uncased&#34;,&#34;attention_probs_dropout_prob&#34;:0.1,&#34;gradient_checkpointing&#34;:false,&#34;hidden_act&#34;:&#34;gelu&#34;,&#34;hidden_dropout_prob&#34;:0.1,&#34;hidden_size&#34;:384,&#34;initializer_range&#34;:0.02,&#34;intermediate_size&#34;:1536,&#34;layer_norm_eps&#34;:1e-12,&#34;max_position_embeddings&#34;:512,&#34;model_type&#34;:&#34;bert&#34;,&#34;num_attention_heads&#34;:12,&#34;num_hidden_layers&#34;:12,&#34;pad_token_id&#34;:0,&#34;position_embedding_type&#34;:&#34;absolute&#34;,&#34;transformers_version&#34;:&#34;4.8.2&#34;,&#34;type_vocab_size&#34;:2,&#34;use_cache&#34;:true,&#34;vocab_size&#34;:30522}&#39;}, &#39;created_time&#39;: 1686603034649, &#39;last_updated_time&#39;: 1686603197066, &#39;last_registered_time&#39;: 1686603047287, &#39;last_deployed_time&#39;: 1686603197066, &#39;total_chunks&#39;: 14, &#39;planning_worker_node_count&#39;: 2, &#39;current_worker_node_count&#39;: 2, &#39;planning_worker_nodes&#39;: [&#39;QkNLom65QCiU1AwA4fRQHA&#39;, &#39;BJ0OvIWHTJuEJu2muBVRIA&#39;], &#39;deploy_to_all_nodes&#39;: True}
</pre></div></div>
</div>
</section>
<section id="Step-5:-Generate-Sentence-Embedding">
<h3>Step 5: Generate Sentence Embedding<a class="headerlink" href="#Step-5:-Generate-Sentence-Embedding" title="Permalink to this heading"></a></h3>
<p>Now using the loaded model in memory, we can generate embedding for sentences. We can provide a list of sentences to get a list of embedding for the sentences.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now using this model we can generate sentence embedding.</span>

<span class="n">input_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Test sentence1&quot;</span><span class="p">,</span> <span class="s2">&quot;Test sentence2&quot;</span><span class="p">]</span>

<span class="n">embedding_output</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">generate_embedding</span><span class="p">(</span><span class="s2">&quot;7KFfsYgBZqn0fcHi8Ku0&quot;</span><span class="p">,</span> <span class="n">input_sentences</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;inference_results&#39;: [{&#39;output&#39;: [{&#39;name&#39;: &#39;sentence_embedding&#39;, &#39;data_type&#39;: &#39;FLOAT32&#39;, &#39;shape&#39;: [384], &#39;data&#39;: [0.070045985, 0.094030164, 0.029469099, 0.006335383, -0.037177853, 0.0034696271, 0.06973787, -0.041374803, -0.05277958, -0.019993568, 0.049499072, 0.0443014, 0.05095634, -0.09186084, -0.039252527, -0.028518854, 0.018059185, -0.097130835, -0.03480089, 0.044088792, 0.025124501, -0.06829837, 0.021070546, 0.073358126, -0.016342998, 0.016885245, 0.0073821708, -0.06980089, 0.019172797, -0.12756695, -0.0028336751, 0.076620854, 0.010953987, 0.04055977, 0.047134332, -0.029655162, -0.025424464, -0.023706172, 0.015665784, -0.00028456873, -0.022526933, -0.073676914, 0.055472963, 0.01868282, 0.039403405, -0.024852037, 0.04160002, -0.0012200676, -0.012104933, -0.051197134, -0.074466705, -0.055452745, 0.0074861553, -0.019089255, -0.030097326, -0.026060734, -0.052988756, 0.067124605, 0.025931405, -0.026440043, -0.006570677, 0.055886537, -0.053474635, 0.007984726, 0.08091788, -0.03664718, -0.03190376, -0.073973835, -0.00654548, 0.03476009, -0.009686864, 0.016051935, -0.047839254, 0.0035186426, -9.659327e-05, -0.03731518, 0.005097011, 0.0046331016, 0.04831959, -0.037194345, -0.018304912, -0.06406546, 0.007127483, 0.0036731786, -0.037867643, 0.0525798, 0.022754213, -0.009397554, -0.0788709, -0.04558914, 0.026581936, -0.07401967, 0.0022031788, 0.027502475, -0.04612981, 0.02867453, 0.02812278, -0.06055298, 0.046777442, 0.19889696, 0.026731564, -0.007961404, -0.064086854, 0.03999534, -0.065743305, -0.01038975, 0.031175181, 0.0015405513, -0.04053732, -0.0026587155, 0.0201725, 0.083728634, 0.005884634, 0.032710858, -0.0015733105, -0.09610316, 0.002357033, 0.05984074, -0.16500355, 0.036792327, 0.12291777, -0.001806536, 0.043636028, -0.04189108, 0.009408711, -0.08278277, 0.12746945, 0.016939184, 0.012635965, -0.146165, 0.051131286, 0.0033628952, -0.022748712, 0.022569735, -0.037459757, 0.018744115, -0.006217754, 0.084697165, -0.006795305, -0.054143608, -0.057388783, 0.047126126, 0.016142208, 0.04754377, -0.062171612, -0.012241133, -0.08141003, -0.01191984, 0.016868386, 0.013309095, 0.0659549, 0.02784064, 0.013731603, -0.05787209, -0.026792012, 0.018663717, -0.050591003, -0.02040348, 0.047714904, -0.016063442, -0.10401469, 0.13376768, -0.030586442, 0.0010340372, 0.070359856, -0.013292282, -0.015457728, 0.048926532, -0.011410942, -0.052058127, 0.18224765, 0.0035982048, 0.02246424, -0.0030590945, -0.019338036, 0.00026652194, 0.022335682, 0.07469184, 0.02382239, 0.01046695, 0.03009087, -0.006465016, -0.051522683, 0.019980922, -0.03548732, 0.010370418, -0.08818134, -0.028292583, 0.074272536, 0.08402995, 0.035817318, -0.018850267, 0.031453982, 0.06855093, 0.014118732, -0.07007131, 0.008944237, 0.01816519, -0.07784689, -0.07069612, -0.012862535, -0.015138116, -0.03347607, -0.0068311035, -0.002638591, 0.036386125, 0.03143706, -0.08959042, 0.053561244, -0.08690694, -0.014790011, 0.055373162, -0.11275848, -0.038676344, 0.01777759, -0.0624037, 0.08309957, -0.058959704, 0.02146699, -0.0052596424, -0.03967568, -0.07005087, 0.0535649, 1.1060871e-32, 0.0013608177, 0.106175095, -0.05951191, -0.0037961602, 0.013185205, -0.046274826, 0.10418064, -0.0012341454, -0.0131508345, 0.018092377, 0.0054246127, 0.014041023, 0.036791388, 0.016286977, -0.09607988, 0.015155129, 0.023281448, 0.0831054, 0.00065585395, 0.0002872294, 0.049073815, 0.050753243, -0.0048564766, 0.08584035, -0.049346138, 0.010288568, 0.08767223, -0.0668006, -0.02730152, -0.06031797, 0.08574493, 0.0017309934, 0.004164226, 0.13996643, -0.0064810724, -0.06346753, 0.106137946, -0.06602096, 0.007606502, 0.034102228, 0.015871577, 0.034030348, -0.06620869, 0.061993707, -0.016627932, -0.001730041, 0.025229787, -0.0031807858, 0.04901121, 0.00089508446, -0.039892998, 0.0016668648, -0.012777798, 0.015382705, 0.016362779, -0.02404705, -0.021434382, -0.09117077, -0.05373932, -0.018560624, 0.023284905, 0.0031982018, -0.0031510415, 0.10734427, 0.06998923, -0.0027732637, -0.0530556, 0.023547022, 0.025985928, -0.035036553, -0.058912452, -0.029204743, 0.008312955, -0.056485176, -0.014061077, 0.04225055, -0.08007323, -0.0091617135, -0.018469298, -0.04556874, -0.015968537, -0.014121485, 0.0036195326, 0.027108386, 0.03586916, -0.01750429, 0.10870282, -0.0083625065, 0.014823508, 0.04874035, 0.010967432, 0.018752282, -0.046599686, -0.05806444, -0.029174872, 4.6263226e-33, -0.03030781, -0.06679235, 0.0005264349, 0.045648444, 0.10910713, -0.016406672, -0.006509885, -0.16902378, 0.011055921, 0.036133043, 0.050960954, 0.028546343, -0.07644701, 0.08252433, -0.041281033, 0.0342127, -0.001389836, 0.0062635387, -0.04514362, -0.01706786, 0.07922916, -0.022634191, -0.06849333, -0.007873758, 0.030855168, 0.036613345, 0.01543812, 0.041089304, -0.05730519, 0.06317529, 0.08143371, 0.07131982, -0.037264705, -0.058889233, -0.049804617, -0.034103516, 0.06648858, -0.014449709, 0.022788258, 0.03571679, -0.03570635, 0.046074998, 0.0053664967, 0.024858603, 0.025428161, -0.010590862, -0.040552795, -0.06513859, -0.0003934997, -0.056372937, -0.05148246, 0.011264148, 0.06645999, 0.026652971, 0.07176414, 0.035537906, 0.03287273, -0.0017281885, -0.079337545, 0.049712148, 0.06649142, 0.06070372, -0.012733799, -0.0060011027]}]}, {&#39;output&#39;: [{&#39;name&#39;: &#39;sentence_embedding&#39;, &#39;data_type&#39;: &#39;FLOAT32&#39;, &#39;shape&#39;: [384], &#39;data&#39;: [0.07083514, 0.098972656, 0.023528868, 0.015548298, -0.03414622, 0.024773195, 0.060273148, -0.028832981, -0.09044978, -0.029630601, 0.044647824, 0.020695554, 0.0451399, -0.105178855, -0.03574795, -0.022011578, 0.02242477, -0.06875169, -0.041503854, 0.046235904, 0.025888842, -0.058203552, 0.0317196, 0.064302124, -0.030310726, 0.027002888, -0.0028196487, -0.044340227, 0.032432694, -0.11670581, 0.014379569, 0.06432164, -0.011770892, 0.032793347, 0.04387399, -0.038692925, -0.013582388, -0.026226582, 0.0076006465, -0.027217122, -0.034419663, -0.08012475, 0.05472637, 0.0074604633, 0.047486894, -0.025225092, 0.037482392, 0.0020973443, -0.0042126533, -0.057536595, -0.08447187, -0.043337554, 0.014264286, -0.023134142, -0.029479904, -0.03363044, -0.05907903, 0.06964192, 0.035337694, -0.022371998, -0.021929951, 0.062269177, -0.030993886, 0.0076106074, 0.07694969, -0.017912427, -0.044359725, -0.056732178, -0.015525767, 0.032636724, -0.009579165, 0.018426858, -0.054791622, 0.008909622, 0.0063452916, -0.0313364, 0.005820822, -0.008221157, 0.058385953, -0.047120888, -0.0052236924, -0.06515579, 0.0010107595, 0.020413563, -0.041749377, 0.044107597, 0.008662938, -0.011051114, -0.08871864, -0.04507809, 0.036184292, -0.07195325, 0.009203214, 0.023508972, -0.028275426, 0.028231027, 0.003911504, -0.070118375, 0.058573272, 0.20727791, 0.048356153, -0.0018830848, -0.066115424, 0.022906033, -0.061623204, -0.021237886, 0.018174624, -0.0050362684, -0.023906242, -0.002387967, 0.035721593, 0.10048729, -0.007958879, 0.044000257, 0.0103866365, -0.09361922, 0.011654698, 0.06738684, -0.1736049, 0.03254977, 0.13699506, -0.0092994645, 0.04818335, -0.050219133, 0.005542939, -0.10294832, 0.10766475, 0.015173319, 0.013554773, -0.13501169, 0.045765, 0.021902261, -0.033359535, 0.028230267, -0.04085567, 0.0077474224, -0.036401946, 0.092795655, -0.00096511975, -0.059694305, -0.035620503, 0.037294034, 0.0015283289, 0.034953, -0.04880616, -0.0059092464, -0.060103483, -0.008989362, 0.022295682, 0.022184573, 0.04979118, 0.049196165, 0.03790123, -0.053590335, -0.0077016405, 0.003188551, -0.056628674, -0.027927972, 0.060124118, -0.025649551, -0.09657911, 0.1299167, -0.032081775, -0.0060925665, 0.06273658, -0.025575282, -0.0069705267, 0.050369203, -0.025092889, -0.019692965, 0.17965682, 0.006651051, 0.024963867, -0.018071478, -0.016473701, -0.00877558, 0.04949933, 0.07836956, 0.03252581, -0.007377615, 0.03200573, -0.011032086, -0.028064458, 0.01763287, -0.026994107, 0.00808559, -0.070627235, -0.034461614, 0.05010755, 0.09331023, 0.049584378, -0.021610672, 0.027137306, 0.071931034, -0.013025755, -0.07407564, 0.020584432, 0.01143555, -0.10216391, -0.06688468, 0.019413434, -0.0076031247, -0.03699172, -0.03037342, 0.0014173934, 0.033982094, 0.028674062, -0.080678664, 0.037503026, -0.08438446, -0.00107288, 0.057899155, -0.113598086, -0.018308517, 0.011551393, -0.07234887, 0.09252413, -0.049695067, 0.014780652, -0.0075675673, -0.044519123, -0.061334103, 0.0589534, 8.414513e-33, 0.009771945, 0.12160786, -0.03935934, -0.010013683, 0.008984462, -0.048829008, 0.092219844, 0.0024215193, -0.008333239, 0.03851628, 0.012913554, 0.032042034, 0.04166485, 0.00095339265, -0.10857277, 0.024132853, 0.021791779, 0.10197005, 0.009454616, 0.02655147, 0.05246785, 0.06066869, -0.01103198, 0.08555522, -0.04832902, 0.015530094, 0.081544966, -0.07317735, -0.024714837, -0.054873053, 0.07664425, 0.00995868, -0.0126262475, 0.12942667, -0.020951333, -0.071839534, 0.112829536, -0.05635948, -0.00964097, 0.0416308, 0.037358228, 0.029693559, -0.06289643, 0.05327226, -0.012749386, 0.009228852, 0.019423483, 0.004775946, 0.036169004, -0.012142309, -0.019225916, -4.9336504e-05, -0.026529595, 0.012205288, 0.017824031, -0.015235648, -0.018118307, -0.08875225, -0.03372443, -0.020540647, -0.0050654826, -0.001371073, 0.0008696483, 0.11509085, 0.067525595, 0.0014781682, -0.05162725, 0.024478963, 0.02746541, -0.04733127, -0.071528465, -0.033279188, -0.007459125, -0.058763813, -0.04050985, 0.023988923, -0.0877261, -0.0031558173, -0.020018995, -0.041812886, -0.0050884373, -0.01390084, 0.02811135, 0.021810783, 0.013438191, -0.007385128, 0.100511186, -0.0144268125, -0.0046929154, 0.039197326, 0.002359752, 0.015907316, -0.035865612, -0.071099125, -0.01309764, 7.376516e-33, -0.022041496, -0.06963562, -0.022240836, 0.03717517, 0.09121255, -0.009112608, -0.014528304, -0.15407158, 0.005560728, 0.024977768, 0.052556068, 0.014630092, -0.08889645, 0.09537802, -0.03995325, 0.04229064, -0.024341475, 0.009678618, -0.048159223, -0.036069203, 0.059143994, -0.00944305, -0.062726334, 0.0018664591, 0.004131935, 0.03928479, 0.014626856, 0.025103925, -0.05313026, 0.054437604, 0.07312243, 0.059003882, -0.038209524, -0.085269175, -0.06061704, -0.042276274, 0.061298754, -0.016126659, 0.03648384, 0.0263596, -0.020908905, 0.048757087, -0.0046108705, 0.035508107, 0.028468246, -0.009864904, -0.034235284, -0.07204, -0.0005532754, -0.05454473, -0.04248278, 0.014105863, 0.081947, 0.040557176, 0.06266554, 0.040847275, 0.028606374, 0.025837993, -0.07722129, 0.039314467, 0.049470015, 0.05854979, -0.03244549, -0.02478489]}]}]}
</pre></div></div>
</div>
</section>
<section id="Step-6:-Unload-Model">
<h3>Step 6: Unload Model<a class="headerlink" href="#Step-6:-Unload-Model" title="Permalink to this heading"></a></h3>
<p>After generating the embedding if we want we can unload the model from memory. <code class="docutils literal notranslate"><span class="pre">unload_model</span></code> method takes two input.</p>
<ol class="arabic simple">
<li><p>model_id –&gt; Which model we want to unload</p></li>
<li><p>node_ids –&gt; list of the nodes from where we want to unload the model.</p></li>
</ol>
<p>If we don’t provide <code class="docutils literal notranslate"><span class="pre">node_ids</span></code> then method will unload model from all the nodes available like the following example.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">undeploy_model_response</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">undeploy_model</span><span class="p">(</span><span class="s2">&quot;7KFfsYgBZqn0fcHi8Ku0&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">undeploy_model_response</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;BJ0OvIWHTJuEJu2muBVRIA&#39;: {&#39;stats&#39;: {&#39;7KFfsYgBZqn0fcHi8Ku0&#39;: &#39;undeployed&#39;}}, &#39;LnxY8AMlTpecPVBSiTOYWg&#39;: {&#39;stats&#39;: {&#39;7KFfsYgBZqn0fcHi8Ku0&#39;: &#39;not_found&#39;}}, &#39;U6Y1_KIrRJuUbcu89tDIWg&#39;: {&#39;stats&#39;: {&#39;7KFfsYgBZqn0fcHi8Ku0&#39;: &#39;not_found&#39;}}, &#39;QkNLom65QCiU1AwA4fRQHA&#39;: {&#39;stats&#39;: {&#39;7KFfsYgBZqn0fcHi8Ku0&#39;: &#39;undeployed&#39;}}}
</pre></div></div>
</div>
</section>
<section id="Step-7:-Delete-Model">
<h3>Step 7: Delete Model<a class="headerlink" href="#Step-7:-Delete-Model" title="Permalink to this heading"></a></h3>
<p>We can also delete the model from the index using the model id.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">delete_model_response</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">delete_model</span><span class="p">(</span><span class="s2">&quot;7KFfsYgBZqn0fcHi8Ku0&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">delete_model_response</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;_index&#39;: &#39;.plugins-ml-model&#39;, &#39;_id&#39;: &#39;7KFfsYgBZqn0fcHi8Ku0&#39;, &#39;_version&#39;: 11, &#39;result&#39;: &#39;deleted&#39;, &#39;_shards&#39;: {&#39;total&#39;: 2, &#39;successful&#39;: 2, &#39;failed&#39;: 0}, &#39;_seq_no&#39;: 24, &#39;_primary_term&#39;: 1}
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="demo_tracing_model_torchscript_onnx.html" class="btn btn-neutral float-left" title="Demo Notebook to trace Sentence Transformers model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../reference/pre_trained_models.html" class="btn btn-neutral float-right" title="Pre-trained models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Opensearch.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>